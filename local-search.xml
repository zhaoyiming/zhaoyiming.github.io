<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Speeding Your Model Training</title>
    <link href="/2022/07/30/2022-07-30-Speeding-your-Model-Training/"/>
    <url>/2022/07/30/2022-07-30-Speeding-your-Model-Training/</url>
    
    <content type="html"><![CDATA[<p>Time is very precious for deep learning engineers. A typical time cost for model training could be divided into three parts:</p><ul><li><strong>Data Loading</strong></li><li><strong>Forward Propagation</strong></li><li><strong>Backward Propagation</strong></li></ul><p>It is essential to reduce the time cost of data reading when GPU resource is enough and fixed. The data loading time could be reduced to less than 0.001s for a batch(8 samples), and the latter two procedures could cost 0.16s and 0.23s. However, any extra operation for training data(i.e., chunk data) would directly bring more time costs for every batch. To reduce the whole training time cost, you cloud to improve the training process from the following two aspects. </p><h2 id="Save-Data-to-HDF5"><a href="#Save-Data-to-HDF5" class="headerlink" title="Save Data to HDF5"></a>Save Data to HDF5</h2><p>To alleviate the real-time communication expense between memory and disks, saving your fragment files to a whole file is better to reduce the retrieval overhead. HDF5 is an ideal saving file format for massive data. Following are some detailed procedures in saving data to an HDF5:</p><h3 id="Speeding-data-saving-by-multiprocessing"><a href="#Speeding-data-saving-by-multiprocessing" class="headerlink" title="Speeding data saving by multiprocessing"></a>Speeding data saving by multiprocessing</h3><h4 id="Obtaining-data-list"><a href="#Obtaining-data-list" class="headerlink" title="Obtaining data list"></a>Obtaining data list</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generate_list</span><span class="hljs-params">(from_path, target_path)</span>:</span><br>    <span class="hljs-string">"""generate train data lists from data path.<br><br>    Args:<br>        from_path (string): data path<br>        target_path (sring): list path<br>    """</span><br><br>    files=os.listdir(from_path)<br>    files_list=[]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> files:<br>        files_list.append(i)<br>    <br>    train_list=files_list[:<span class="hljs-number">70000</span>]<br>    dev_list=files_list[<span class="hljs-number">70000</span>:<span class="hljs-number">71000</span>]<br><br>    <span class="hljs-keyword">with</span> open(target_path+<span class="hljs-string">"train_temp.scp"</span>, <span class="hljs-string">"w"</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> train_list:<br>            f.write(i+<span class="hljs-string">" "</span>+from_path+<span class="hljs-string">"/"</span>+i+<span class="hljs-string">"\n"</span>)<br>    <span class="hljs-keyword">with</span> open(target_path+<span class="hljs-string">"dev_temp.scp"</span>, <span class="hljs-string">"w"</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> dev_list:<br>            f.write(i+<span class="hljs-string">" "</span>+from_path+<span class="hljs-string">"/"</span>+i+<span class="hljs-string">"\n"</span>)<br>    print(<span class="hljs-string">"-----generate_list down-----"</span>)<br></code></pre></td></tr></table></figure><h4 id="Splitting-the-training-data-list-to-several-lists"><a href="#Splitting-the-training-data-list-to-several-lists" class="headerlink" title="Splitting the training data list to several lists"></a>Splitting the training data list to several lists</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">split_scp</span><span class="hljs-params">(from_path, target_path, file_num)</span>:</span><br>    <span class="hljs-string">"""Splitting big trainging list to multiple file to parallel extract features <br><br>    Args:<br>        from_path (string): to be splited file path<br>        target_path (string): chunk files path<br>        file_num (int): number to be splited<br>    """</span><br><br>    f = open(from_path, <span class="hljs-string">"r"</span>)<br>    lines = f.readlines()  <br>    n = math.ceil(len(lines)/file_num)<br>    output = [lines[i:i + n] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, len(lines), n)]<br><br>    <span class="hljs-keyword">for</span> small <span class="hljs-keyword">in</span> range(len(output)):<br>        print(<span class="hljs-string">"train"</span>+str(small)+<span class="hljs-string">".scp: "</span>,len(output[small]))<br>        <span class="hljs-keyword">with</span> open(target_path + <span class="hljs-string">"train"</span>+str(small)+<span class="hljs-string">".scp"</span>, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> output[small]:<br>                f.write(i)<br>    print(<span class="hljs-string">"-----split_scp down-----"</span>)<br></code></pre></td></tr></table></figure><h4 id="Saving-your-data-to-HDF5"><a href="#Saving-your-data-to-HDF5" class="headerlink" title="Saving your data to HDF5"></a>Saving your data to HDF5</h4><p>Read data from your data list in the following code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">data_load</span><span class="hljs-params">()</span>:</span><br>       data_dict=&#123;i:[] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> [<span class="hljs-string">"key1"</span>, <span class="hljs-string">"key2"</span>]&#125;<br>       <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> datalist:<br>           eg=data_read(data) <span class="hljs-comment"># for read data</span><br>           chunks = self.splitter.split(eg) <span class="hljs-comment"># for chunk </span><br>           <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> chunks:<br>               <span class="hljs-keyword">for</span> cell <span class="hljs-keyword">in</span> [<span class="hljs-string">"key1"</span>, <span class="hljs-string">"key2"</span>]:<br>               data_dict[cell].append(i[cell])<br><br>        batch = &#123;<br>                key: np.stack(data_dict[key], axis=<span class="hljs-number">0</span>).astype(np.float32)<br>                <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> [<span class="hljs-string">"key1"</span>, <span class="hljs-string">"key2"</span>]<br>        &#125;<br>       <br>        <span class="hljs-keyword">with</span> h5py.File(to_file, <span class="hljs-string">'a'</span>) <span class="hljs-keyword">as</span> fw:<br>            fw[<span class="hljs-string">"key1"</span>], fw[<span class="hljs-string">"key2"</span>] = batch[<span class="hljs-string">"key1"</span>], batch[<span class="hljs-string">"key2"</span>]<br>            print(<span class="hljs-string">f'saving '</span> + str(len(data_dict[<span class="hljs-string">"key1"</span>])) + <span class="hljs-string">' data to '</span>+to_file)<br>        fw.close()<br></code></pre></td></tr></table></figure><h4 id="Multiprocessing"><a href="#Multiprocessing" class="headerlink" title="Multiprocessing"></a>Multiprocessing</h4><p>Utilizing the multiprocessing method in python to extract data to multiple hdf5 files:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_ming</span><span class="hljs-params">(scp, to_file, training)</span>:</span><br>    <span class="hljs-string">"""Multiple proecess to parallel extract feature<br><br>    Args:<br>        scp (string): child process file<br>        training (bool): is training<br>    """</span><br>    dataload(xxx, xxx)<br><br><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process<br>process_num=<span class="hljs-number">10</span> <span class="hljs-comment"># processes you want to paralell run</span><br>processes = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(process_num):<br>  p = Process(target=process_ming,<br>              args=(xxx,xxx))<br>  p.start()<br>  print(<span class="hljs-string">f'process '</span>+ str(i) +<span class="hljs-string">' has started'</span>)<br>  processes.append(p)<br><br><span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> processes:<br>    p.join()<br></code></pre></td></tr></table></figure><h4 id="Merge-hdf5-files-to-one"><a href="#Merge-hdf5-files-to-one" class="headerlink" title="Merge hdf5 files to one"></a>Merge hdf5 files to one</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">h52binh5</span><span class="hljs-params">(from_path, to_file)</span>:</span><br>    <span class="hljs-string">""" Combining multiple small h5 files to a whole h5 file<br><br>    Args:<br>        path (string): path that store all small h5 files<br>    """</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(os.path.dirname(to_file)):<br>        os.mkdir(os.path.dirname(to_file))<br><br>    <span class="hljs-keyword">for</span> root, dirs, files <span class="hljs-keyword">in</span> os.walk(from_path):<br>        <span class="hljs-keyword">with</span> h5py.File(os.path.join(root, files[<span class="hljs-number">0</span>]), <span class="hljs-string">'r'</span>) <span class="hljs-keyword">as</span> f1:<br>            attributs = list(f1.keys())<br>        f1.close()<br><br>        data = &#123;attribut: [] <span class="hljs-keyword">for</span> attribut <span class="hljs-keyword">in</span> attributs&#125;<br>        <span class="hljs-keyword">for</span> attribut <span class="hljs-keyword">in</span> attributs:<br>            <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> sorted(files):<br>                <span class="hljs-keyword">with</span> h5py.File(os.path.join(root, file), <span class="hljs-string">'r'</span>) <span class="hljs-keyword">as</span> f2:<br>                    data[attribut].append(f2[attribut][...])<br>                f2.close()<br>            temp=np.concatenate(data[attribut], axis=<span class="hljs-number">0</span>)<br>            print(attribut+<span class="hljs-string">" : "</span>+ str(temp.shape[<span class="hljs-number">0</span>]))<br>            <span class="hljs-keyword">with</span> h5py.File(to_file, <span class="hljs-string">"a"</span>) <span class="hljs-keyword">as</span> fw:<br>                fw[attribut] = temp<br>            fw.close()<br>            <span class="hljs-keyword">del</span> temp<br>    print(<span class="hljs-string">"-----combining h5 files down-----"</span>)<br></code></pre></td></tr></table></figure><h3 id="Customize-your-dataset-for-reading-HDF5"><a href="#Customize-your-dataset-for-reading-HDF5" class="headerlink" title="Customize your dataset for reading HDF5"></a>Customize your dataset for reading HDF5</h3><p>Customize your PyTorch dataset to extract data from HDF5:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">myDataset</span><span class="hljs-params">(Dataset)</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, file)</span>:</span><br>        self.fw=h5py.File(file, <span class="hljs-string">'r'</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span><br>        <span class="hljs-keyword">return</span> len(self.fw[<span class="hljs-string">"key1"</span>])<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(self, idx)</span>:</span><br>        <span class="hljs-keyword">return</span> torch.tensor(self.fw[<span class="hljs-string">"key1"</span>][idx], dtype=torch.float32), torch.tensor(self.fw[<span class="hljs-string">"key2"</span>][idx], dtype=torch.float32)<br></code></pre></td></tr></table></figure><h3 id="Ultizing-MultiPorcess-to-Improve-Costing-Operation"><a href="#Ultizing-MultiPorcess-to-Improve-Costing-Operation" class="headerlink" title="Ultizing MultiPorcess to Improve Costing Operation"></a>Ultizing MultiPorcess to Improve Costing Operation</h3><p>Avoid processing or chunking your data during the training procedure. Operation for training data would bring unmeaningful time cost, and this costing operation is challenging to parallel. Therefore, moving these operations to the data preparation stage could reduce training time. </p><h2 id="DP-amp-DDP"><a href="#DP-amp-DDP" class="headerlink" title="DP &amp; DDP"></a>DP &amp; DDP</h2><h3 id="Data-Parallel"><a href="#Data-Parallel" class="headerlink" title="Data Parallel"></a>Data Parallel</h3><p>Speeding model training by DP as following:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model = torch.nn.DataParallel(model)<br></code></pre></td></tr></table></figure><p>What’s more? Put some data operation to be speeded by Cuda on your first GPU.</p><h3 id="Distributed-Data-Parallel"><a href="#Distributed-Data-Parallel" class="headerlink" title="Distributed Data Parallel"></a>Distributed Data Parallel</h3><p>Speeding model training by DDP as following:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.distributed <span class="hljs-keyword">as</span> dist<br><span class="hljs-keyword">from</span> torch.nn.parallel <span class="hljs-keyword">import</span> DistributedDataParallel <span class="hljs-keyword">as</span> DDP<br><span class="hljs-keyword">import</span> argparse<br><br>parser = argparse.ArgumentParser()<br>parser.add_argument(<span class="hljs-string">"--local_rank"</span>,default=<span class="hljs-number">-1</span>, type=int)<br>args = parser.parse_args()<br><br>torch.cuda.set_device(args.local_rank)<br>torch.distributed.init_process_group(backend=<span class="hljs-string">'nccl'</span>)<br>nnet=model()<br><br>train_dataset=myDataset(args.train_data)<br>dev_dataset=myDataset(args.dev_data)<br><br>train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, rank=args.local_rank, shuffle=<span class="hljs-keyword">True</span>)<br>dev_sampler =torch.utils.data.distributed.DistributedSampler(dev_dataset, rank=args.local_rank, shuffle=<span class="hljs-keyword">False</span>) <br><br>train_loader = DataLoader(<br>    dataset=train_dataset,<br>    sampler=train_sampler,<br>    batch_size=args.batch_size,<br>    num_workers=<span class="hljs-number">16</span>,<br>    pin_memory=<span class="hljs-keyword">True</span>,<br>    drop_last=<span class="hljs-keyword">False</span><br>)<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Trainer</span><span class="hljs-params">(object)</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,<br>                 nnet,<br>                 rank,<br>                 )</span>:</span><br>        self.rank=rank,<br>        self.device = th.device(<span class="hljs-string">"cuda"</span>, self.rank[<span class="hljs-number">0</span>])<br>        self.nnet=DDP(nnet.to(self.device), device_ids=[self.rank], output_device=self.rank)<br>    <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save_checkpoint</span><span class="hljs-params">(self, best=True)</span>:</span><br>        cpt = &#123;<br>            <span class="hljs-string">"epoch"</span>: self.cur_epoch,<br>            <span class="hljs-string">"model_state_dict"</span>: self.nnet.module.state_dict(), <span class="hljs-comment"># add .module for ddp</span><br>            <span class="hljs-string">"optim_state_dict"</span>: self.optimizer.state_dict()<br>        &#125;<br>        th.save(<br>            cpt,<br>            os.path.join(self.checkpoint,<span class="hljs-string">"&#123;0&#125;.pt.tar"</span>.format(<span class="hljs-string">"best"</span> <span class="hljs-keyword">if</span> best <span class="hljs-keyword">else</span> <span class="hljs-string">"last"</span>)))<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>NeuralNetwork</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>超声波调制解调信号</title>
    <link href="/2022/03/26/2022-03-26-%E8%B6%85%E5%A3%B0%E6%B3%A2%E8%B0%83%E5%88%B6%E8%A7%A3%E8%B0%83%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7/"/>
    <url>/2022/03/26/2022-03-26-%E8%B6%85%E5%A3%B0%E6%B3%A2%E8%B0%83%E5%88%B6%E8%A7%A3%E8%B0%83%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7/</url>
    
    <content type="html"><![CDATA[<p>完成使用超声波调制发送解调IP地址的任务。</p><h1 id="主要流程"><a href="#主要流程" class="headerlink" title="主要流程"></a>主要流程</h1><p>1、 在电脑使用matlab，将提供的IP转换为32位二进制。将每一位0或1分别调制成480/48000=0.1s的正弦波，进行拼接。</p><p>2、 使用安卓手机发射调制的正弦波，使用麦克风接收声波信号。</p><p>3、 将麦克风收到的信号通过高通滤波器得到高频信号，根据信号的滑动均值和阈值提取收集到的整段信号，将根据信号窗口提取FFT能量作为0或1的解调。</p><p>4、 根据01串还原IP，完成超声波传输IP地址。</p><h1 id="实现效果"><a href="#实现效果" class="headerlink" title="实现效果"></a>实现效果</h1><p>在每秒100bits的情况，传输距离最高1m，超过这个距离接受的质量下降会导致有些bits识别错误，如果把窗口加长为每秒50bits，传输距离可以达到1.8m准确。</p><h1 id="Thinking"><a href="#Thinking" class="headerlink" title="Thinking"></a>Thinking</h1><p>除了分辨率会影响发射距离，发射手机的扬声器和接收手机的麦克风质量都会有影响。</p><p>考虑如何把发射距离提升到10m？</p><ul><li>使用更大功率的发射设备和接收设备</li><li>考虑使用lora调制</li><li>考虑改变发射频率</li></ul><p>目前使用超声波发送调制信号可以使用lora调制，lora调制方法是商业的没有公布源码，可靠的实现可以参考<a href="https://iot-book.github.io/9_LoRa/S2_LoRa%E9%80%9A%E4%BF%A1%E5%AE%9E%E9%AA%8C/" target="_blank" rel="noopener">清华博士的解析和实现</a>。</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="调制发送信号"><a href="#调制发送信号" class="headerlink" title="调制发送信号"></a>调制发送信号</h2><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs undefined">f1 = 17e3;   <br>f2 = 18e3;<br>fs = 48e3;      <br>A=350;<br>time=960;<br>sendSignal = zeros(1, time*32);<br><br>% 把ip转换为二进制<br>ipFields = uint8(str2double(split('173.33.45.29', '.')))'<br>temp=dec2bin(typecast(fliplr(ipFields), 'uint32'))<br>symbal = double(temp)-'0';<br><br>% 根据二进制生成正弦波<br>t = 0:1/fs:(time-1)/fs;<br>for i=symbal<br>    if i==0<br>        temp=A*cos(2*pi*f1*t);<br>    <span class="hljs-keyword">else</span><br>        temp=A*cos(2*pi*f2*t);<br>    end<br>    sendSignal = [sendSignal temp];<br>end<br>plot(sendSignal)<br>stft(sendSignal, fs)<br>dlmwrite(<span class="hljs-string">"send/chirp.txt"</span>, sendSignal')<br></code></pre></td></tr></table></figure><h2 id="解调信号"><a href="#解调信号" class="headerlink" title="解调信号"></a>解调信号</h2><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs undefined">fs=48000;<br>f1 = 17e3;   <br>f2 = 18e3;<br>chirp_len=960;<br>mode='s7/';<br>% 读取文件<br>fileFolder = fullfile(['receive/', mode]);<br>dirOutput = dir(fullfile(fileFolder,'*.pcm'));<br>fileNames = &#123;dirOutput.name&#125;;<br>file_name = fileNames&#123;end&#125;<br>file=['receive/' , mode, file_name];<br>data= importdata(file);<br><br>% 去掉头尾信息<br>data=data(15000:end-50000);<br>stft(data, fs, <span class="hljs-string">"FFTLength"</span>, 1024)<br><br>time = length(data);<br>t = 0:1/fs:(time-1)/fs;<br>% 获得超声波部分<br>data=highpass(data, 15000, fs);<br>% stft(data, fs, <span class="hljs-string">"FFTLength"</span>, 1024)<br><br>% 获得有效数据<br>A = movmean(abs(data), 20);<br>thresh = (max(A) - min(A))/7 + min(A);<br>inds = find(A &gt; thresh);  % 找信号高于thre的下标位置<br>valid_data = data(inds(1):inds(end));  % 截取信号<br>if(length(valid_data)&lt;32*chirp_len)<br>    valid_data=padarray(valid_data,32*chirp_len-length(valid_data), <span class="hljs-string">"pre"</span>);<br><span class="hljs-keyword">else</span><br>    valid_data=valid_data(1:32*chirp_len);<br>end<br>% <br>% stft(valid_data, fs, <span class="hljs-string">"FFTLength"</span>, 1024)<br><br>% 解调01信号<br>res=[];<br>for i= 1:chirp_len:length(valid_data)<br>    temp=valid_data(i:i+chirp_len-1);<br>    [argv, argmin]=max(abs(fft(temp, fs)));<br>    if(abs(argmin-f1)&lt;abs(argmin-f2))<br>        res= [res 0];<br>    <span class="hljs-keyword">else</span><br>        res=[res 1];<br>    end<br>end<br><br>% 转换为ip<br>res;<br>str_res= sprintf('%1d', res)<br>deci_res=bin2dec(str_res)<br>IPVector= deci_res;<br>test=strcat(num2str(bitand(bitshift(IPVector,-24), 255)),'.',num2str(bitand(bitshift(IPVector,-16), 255)) ,'.',num2str(bitand(bitshift(IPVector,-8), 255)) ,'.',num2str(bitand(bitshift(IPVector,0), 255))  )<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Dynamic Network</category>
      
    </categories>
    
    
    <tags>
      
      <tag>模型压缩</tag>
      
      <tag>Dynamic Network</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动态网络研究总结</title>
    <link href="/2021/12/21/2021-12-21-%E5%8A%A8%E6%80%81%E7%BD%91%E7%BB%9C%E7%A0%94%E7%A9%B6%E6%80%BB%E7%BB%93/"/>
    <url>/2021/12/21/2021-12-21-%E5%8A%A8%E6%80%81%E7%BD%91%E7%BB%9C%E7%A0%94%E7%A9%B6%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<p>模型压缩包括量化、网络剪枝、模型蒸馏和网络结构搜索(NAS)，对于轻量化设备部署神经网络比较有意义。网络剪枝包括动态剪枝和静态剪枝，目的为减少计算量以及模型容量。静态剪枝为主流，通过先确定最优网络然后进行物理修建网络以实现网络瘦身，缺点是对于新的样本效果可能不好。动态剪枝类似于NAS，实际效果有待评估。</p><h2 id="为什么要做动态网络"><a href="#为什么要做动态网络" class="headerlink" title="为什么要做动态网络"></a>为什么要做动态网络</h2><ul><li>传统网络只根据固定权重来推理每个样本，不同难度的样本(一张图像中，占画面很大的人和占画面很小的狗需要的网络深度和宽度都不同)输入时会造成资源浪费。</li><li>需要更深的网络，但是保持计算资源不大幅度增加。因为更深的网络有助于网络表达和细粒度推理（更深的网络推理更细粒度的细节）。</li><li>在移动网络下，我们需要节省更多的资源，动态网络可以帮助减少计算所需资源。</li></ul><h2 id="动态网络分类"><a href="#动态网络分类" class="headerlink" title="动态网络分类"></a>动态网络分类</h2><h3 id="Dynamic-Network"><a href="#Dynamic-Network" class="headerlink" title="Dynamic Network"></a>Dynamic Network</h3><p>动态网络包括动态剪枝，也几乎涵括本文中其他主题，请看第一篇survey继续梳理思路。</p><h4 id="Survey类论文"><a href="#Survey类论文" class="headerlink" title="Survey类论文"></a>Survey类论文</h4><ul><li>Dynamic Neural Networks A Survey 非常重要，几乎涵括所有类型的动态网络，先看这篇对所有类型动态网络有一个基本了解。</li><li>Pruning Algorithms to Accelerate Convolutional Neural Networks for Edge 暂时没看，需要时可以参考</li><li>Pruning and quantization for deep neural network acceleration A survey 同上</li></ul><h3 id="Mixture-of-expert"><a href="#Mixture-of-expert" class="headerlink" title="Mixture of expert"></a>Mixture of expert</h3><p>目的大部分是为了通过不增加太多计算的情况下提升网络的可表达性(等同于网络容量)。</p><p>此篇结合知乎理解一些基础：</p><ul><li>OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER</li></ul><p>此篇实验已做，但效果存在疑问，目前只有arxiv，github无代码，我自己改动实现：</p><ul><li>Deep Mixture of Experts via Shallow Embedding</li></ul><p>传统Moe一般结合transformer(有局限性)，由于transformer的encoder在注意力层后面接一层全连接层，所以比较适合将专家层安排在此层。该篇思想比较新颖，通过结合动态网络的思想，将每层网络（每一层卷积层）视为一个gate网络，该层每一个通道视为一个专家。这样整个CNN网络被视为拥有N个gate网络的动态网络，每一层通道都会根据样本来动态选择专家(也就是每一个通道的权重)。</p><p>这种方法的缺点是采用掩模(mask)，通过gate网络生成0和1数列来掩蔽整个卷积层，但是这种方法带来的稀疏性，也就是0不均匀分布(现有机制下，就算我们在该通道事先生成了0，但是我没法控制这个卷积核不进行计算)，是无法实现实际上的加速效果的。</p><p>上一篇论文借鉴的是动态剪枝的内容：</p><ul><li>runtime-neural-pruning</li></ul><p>该篇虽然是动态训练网络掩模，但是是训练后又剪枝，如果看不懂上一篇，可以看这一篇理解掩模和动态剪纸的基础。</p><p>基于以上两篇，我看到了CVPR2021的一篇新内容，github有代码</p><ul><li>Manifold Regularized Dynamic Network Pruning</li></ul><p>idea非常好，是对于gate网络针对不同难度样本采用不同权重等等，但是可能也没有加速效果。</p><h3 id="Slim-Network"><a href="#Slim-Network" class="headerlink" title="Slim Network"></a>Slim Network</h3><p>目的是为了实际加速，缺点是不减少模型容量。</p><p>由于动态网络和混合专家系统拥有稀疏性，但是目前的cuda以及pytroch对稀疏性的支持并不好，其实很难实现真正物理上的加速。Slim network从物理上连续地对卷积核进行掩蔽，所以从理论上可以实现真正的加速，如果要实现真正的效果，要注意这块内容。</p><p><em>先看这个进行粗略了解。</em></p><p>如何评价论文：Slimmable Neural Networks？ - 月臻的回答 - 知乎 <a href="https://www.zhihu.com/question/306865592/answer/872860400" target="_blank" rel="noopener">https://www.zhihu.com/question/306865592/answer/872860400</a></p><h4 id="Slim三部曲"><a href="#Slim三部曲" class="headerlink" title="Slim三部曲"></a>Slim三部曲</h4><ul><li>slimmable_neural_networks</li><li>Universally_Slimmable_Networks_and_Improved_Training_Techniques</li><li>AutoSlim: Towards One-Shot Architecture Search for Channel Numbers 无附件。</li></ul><p>重点关注前两部，第一部基础，第二部重大改进。</p><h4 id="新型Slim"><a href="#新型Slim" class="headerlink" title="新型Slim"></a>新型Slim</h4><ul><li>dynamic slim </li></ul><p>cvpr2021的一篇新作品，结合动态网络和slim进行有效加速，暂时没有深究，也是一个重点。</p><h3 id="Condconv"><a href="#Condconv" class="headerlink" title="Condconv"></a>Condconv</h3><p>主要为增加网络性能，增加少量计算量，大量增加模型容量(需要优化)，也比较有前途。</p><p>是动态网络的一种，和专家系统的原理非常相似，有点专家系统和动态网络结合的感觉。传统神经网络每一层只有一套固定的卷积核，condconv首先赋予每个卷积层多套权重，然后通过一个门控网络(gate network)来对输入的每一个样本选择不同的专家(expert，这里指代不同的卷积核权重)，通过加权求和得到一个卷积核权重，再将卷积核与样本进行卷积。（这样做的好处就是，只增加了gate网络的计算量，就把整个网络的容量和可表达性进行增加。）</p><p>一般来说对于移动端的层数比较低的网络效果比较好，有实验结果，确实有一定效果，参数搜索比较麻烦，计算量要控制好。</p><p>论文有三个同时出现的论文，为谷歌 华为研究院和MSRA同时出现，各有优劣，基本原理相同，了解主要看condconv即可，深入都要看</p><ul><li>CondConv: Conditionally Parameterized Convolutions for Efficient Inference</li><li>DYNET: DYNAMIC CONVOLUTION FOR ACCELERATING CONVOLUTION NEURAL NETWORKS</li><li>Dynamic Convolution: Attention over Convolution Kernels</li></ul><p>还有一篇改进</p><ul><li>WeightNet: Revisiting the Design Space of Weight Networks</li></ul><p>将condconv和SE-Net结合。</p><p>SE-Net是一种使用注意力机制来赋予通道高注意力的网络结构，极其有效，请务必先了解，condconv实际上是用注意力机制在多套卷积核上而不是通道上。</p><h2 id="已有探索部分"><a href="#已有探索部分" class="headerlink" title="已有探索部分"></a>已有探索部分</h2><ul><li><p>Dynamic network和专家系统部分，专家系统需要大量计算能力，几乎无法实验，但是需要完全了解moe的机制才能进行类似研究。我个人做了google 的deep moe(等同于使用专家系统(目的提高性能)来做动态剪枝)，有效果，有图层分析，但是没有看到加速效果，需要深入了解。</p></li><li><p>Condconv这边做了三篇论文的比较实验，设计了一种比较特殊的condconv，有效果但是不稳定，需要重复论证，需要补充在moblienet上面的实验， 如果发论文需要在cifar10 cifar100和Imagenet,初期只需要在cifar10上面做实验。</p></li><li><p>slim还没有进行实验，比较看好。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Dynamic Network</category>
      
    </categories>
    
    
    <tags>
      
      <tag>模型压缩</tag>
      
      <tag>Dynamic Network</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Restore raw latex file from existing pdf</title>
    <link href="/2021/08/06/2021-08-06-Restore%20raw%20latex%20file%20from%20existing%20pdf/"/>
    <url>/2021/08/06/2021-08-06-Restore%20raw%20latex%20file%20from%20existing%20pdf/</url>
    
    <content type="html"><![CDATA[<p>Maybe you have lost the raw latex file due to some strange reasons. Unforturenatly, there is no some simple way to rapidly restore the raw Tex code from the compiled pdf(Portable Document Format) file. Don’t be upset, Let’s restore it as far as possible. </p><h2 id="Text"><a href="#Text" class="headerlink" title="Text"></a>Text</h2><p>First of all, the restoration of text from the pdf file is simple but tedious. Nevertheless, there are also some troubles, it needs to choose a strong pdf reader to avoid the problem that the copied text with format from some pdf reader may cause the complicated layout and unnecessary space. This blog opens the pdf file by Adobe Acrobat and saves it as the docx file, then you can copy the text without any format to the Tex file from the docx file.</p><h2 id="Image"><a href="#Image" class="headerlink" title="Image"></a>Image</h2><p>Since the images are not embedded inside a pdf file but saved as raw binary code, it is not easy to extract raw images from an existing pdf file. If you need to get vector graphics, the simplest way is that extract vector graphics from the pdf file by some vector software, i.e., Affinity Designers, Inkscape, Adobe Illustrator. This blog chooses Affinity Designers(Paid Software) because it is convenient to choose vector graphics and extract them.</p><h2 id="Table"><a href="#Table" class="headerlink" title="Table"></a>Table</h2><p>This blog chooses <a href="tablesgenerator.com">tablesgenerator</a> to rapidly restore tables of lost paper. Firstly, we obtain the docx file as the Text section. Then we copy a table and save it as a CSV file. Next, we upload the CSV file to the website and adjust the format. Finally, you can copy the generated code to the Tex file.</p><h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><p>The restoration of Algorithm is similar to the Text Section. It is best to copy text from the generated docx file. Note that  algorithm2e package is easier to use than algorithm with algorithmicx.</p><h2 id="Equation"><a href="#Equation" class="headerlink" title="Equation"></a>Equation</h2><p><a href="https://mathpix.com/" target="_blank" rel="noopener">Mathpix Snip</a> is a great OCR software to covert images of mathematical formulas to Tex code or other formats such as word. It is easy to accurately get raw Tex code of mathematical equations through the software.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>About references, we recommend that: </p><ol><li>Search all references through Google Scholar and save them(Click the star icon below the document item).</li><li>Open ‘My library’ and export all items in the BibTeX format in Google Scholar.</li><li>Then, you can use a BibTeX file to manage cited references or <a href="https://tex.stackexchange.com/questions/124874/converting-to-bibitem-in-latex" target="_blank" rel="noopener">convert them to Bibitem</a>.</li></ol>]]></content>
    
    
    <categories>
      
      <category>Paper</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Paper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MultiProcessing of DL in PyTorch</title>
    <link href="/2021/07/23/2021-07-23-MultiProcessing/"/>
    <url>/2021/07/23/2021-07-23-MultiProcessing/</url>
    
    <content type="html"><![CDATA[<p>This article helps to handle DL tasks(e.g., extract and save embedding) base on multiprocess and multi-GPU in PyTorch. </p><p>Thought：Difference to the ddp。</p><h3 id="Include-libs"><a href="#Include-libs" class="headerlink" title="Include libs"></a>Include libs</h3><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-keyword">import</span> GPUtil<br><span class="hljs-title">from</span> torch.multiprocessing <span class="hljs-keyword">import</span> Process<br></code></pre></td></tr></table></figure><h3 id="Initial-Parameters"><a href="#Initial-Parameters" class="headerlink" title="Initial Parameters"></a>Initial Parameters</h3><figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">use_gpu=<span class="hljs-literal">True</span> // <span class="hljs-keyword">use</span> GPU <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span><br>world_size=<span class="hljs-number">1</span> // the number <span class="hljs-keyword">of</span> allocated GPU <span class="hljs-keyword">and</span> <span class="hljs-keyword">Process</span><br></code></pre></td></tr></table></figure><h3 id="Structured-Functions"><a href="#Structured-Functions" class="headerlink" title="Structured Functions"></a>Structured Functions</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">extract</span><span class="hljs-params">(<span class="hljs-keyword">self</span>)</span></span>:<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.<span class="hljs-symbol">parallel_extract_list:</span><br>            <span class="hljs-keyword">self</span>.parallel_extract()<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.<span class="hljs-symbol">sequential_extract_list:</span><br>            <span class="hljs-keyword">self</span>.sequential_extract()<br></code></pre></td></tr></table></figure><h3 id="parallel-extract"><a href="#parallel-extract" class="headerlink" title="parallel_extract()"></a>parallel_extract()</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parallel_extract</span><span class="hljs-params">(<span class="hljs-keyword">self</span>)</span></span>:<br>        t<span class="hljs-number">0</span> = time.time()<br>        <span class="hljs-keyword">for</span> extract_file, save_to_dir <span class="hljs-keyword">in</span> <span class="hljs-keyword">self</span>.<span class="hljs-symbol">parallel_extract_list:</span><br><br>       <span class="hljs-comment"># spilt the huge file to several parts according to world_size</span><br>            df = pd.read_csv(extract_file)<br>            dfs = np.array_split(df, <span class="hljs-keyword">self</span>.world_size)<br>            <br>            <span class="hljs-comment"># get max gpu nums</span><br>            gpu_ids = GPUtil.getAvailable(maxMemory=<span class="hljs-number">0</span>.<span class="hljs-number">02</span>,<br>                                          limit=<span class="hljs-keyword">self</span>.world_size)<br>            processes = []<br>            <span class="hljs-keyword">for</span> rank, gpu_id <span class="hljs-keyword">in</span> enumerate(gpu_ids):<br>                p = Process(target=<span class="hljs-keyword">self</span>._parallel_extract,<br>                            args=(f<span class="hljs-string">'&#123;save_to_dir&#125;/res_&#123;rank&#125;.h5'</span>, dfs[rank], gpu_id, rank))<br>                p.start()<br>                print(f<span class="hljs-string">'process &#123;rank&#125; has started'</span>)<br>                processes.append(p)<br>    <br>            <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> <span class="hljs-symbol">processes:</span><br>                p.join()<br>        print(f<span class="hljs-string">'total time is &#123;(time.time() - t0) / 60&#125;'</span>)<br><br><br>​        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_parallel_extract</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, save_to_dir, csv_file, gpu_id, rank)</span></span>:<br>    <br>    <span class="hljs-comment"># allocate gpu for every child_process</span><br>        <span class="hljs-keyword">self</span>.device = torch.device(gpu_id)<br>        <br>    <span class="hljs-comment"># load model</span><br>        <span class="hljs-keyword">self</span>.params[<span class="hljs-string">"embedding_model"</span>].to(<span class="hljs-keyword">self</span>.device)<br>    <br>        <span class="hljs-comment"># prep dataloader</span><br>        test_dataloader = <span class="hljs-keyword">self</span>.dataio_prep(csv_file)<br>        <br>        <span class="hljs-comment"># In general, _extraction extracts embeeding and return specific column.</span><br>        with h5py.File(save_to_dir, <span class="hljs-keyword">self</span>.mode) as <span class="hljs-symbol">fw:</span><br>            fw[<span class="hljs-string">'X'</span>], fw[<span class="hljs-string">'n_frames'</span>], fw[<span class="hljs-string">'spk_ids'</span>], fw[<span class="hljs-string">'spk_path'</span>] = <span class="hljs-keyword">self</span>._extraction(save_to_dir, test_dataloader)<br>        print(f<span class="hljs-string">'saving embedding'</span>)<br></code></pre></td></tr></table></figure><h3 id="sequential-extract"><a href="#sequential-extract" class="headerlink" title="sequential_extract()"></a>sequential_extract()</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sequential_extract</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, gpu_id=None)</span></span>:<br><span class="hljs-regexp">/*allocate device according to parameters*/</span><br>       <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-symbol">gpu_id:</span><br>           <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.<span class="hljs-symbol">use_gpu:</span><br>               gpu_id = GPUtil.getAvailable(maxMemory=<span class="hljs-number">0</span>.<span class="hljs-number">02</span>,<br>                                            order=<span class="hljs-string">'last'</span>,<br>                                            limit=<span class="hljs-keyword">self</span>.world_size)[<span class="hljs-number">0</span>]<br>               <span class="hljs-keyword">self</span>.device = torch.device(gpu_id)<br>           <span class="hljs-symbol">else:</span><br>               <span class="hljs-keyword">self</span>.device = torch.device(<span class="hljs-string">'cpu'</span>)<br>       <span class="hljs-symbol">else:</span><br>           <span class="hljs-keyword">self</span>.device = torch.device(gpu_id)<br><br>       <span class="hljs-keyword">self</span>._sequential_extract()<br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_sequential_extract</span><span class="hljs-params">(<span class="hljs-keyword">self</span>)</span></span>:<br>       t<span class="hljs-number">0</span> = time.time()<br>       <span class="hljs-keyword">for</span> csv_file, save_to_dir <span class="hljs-keyword">in</span> <span class="hljs-keyword">self</span>.<span class="hljs-symbol">sequential_extract_list:</span><br>           <span class="hljs-comment"># prep dataloader</span><br>           test_dataloader = <span class="hljs-keyword">self</span>.dataio_prep(csv_file)<br><br>           <span class="hljs-comment"># load model and allocate device</span><br>           <span class="hljs-keyword">self</span>.params[<span class="hljs-string">"embedding_model"</span>].to(<span class="hljs-keyword">self</span>.device)<br>           <br>           <span class="hljs-comment"># In general, _extraction extracts embeeding and return specific column.</span><br>           with h5py.File(save_to_dir, <span class="hljs-keyword">self</span>.mode) as <span class="hljs-symbol">fw:</span><br>               fw[<span class="hljs-string">'X'</span>], fw[<span class="hljs-string">'n_frames'</span>], fw[<span class="hljs-string">'spk_ids'</span>], fw[<span class="hljs-string">'spk_path'</span>] = <span class="hljs-keyword">self</span>._extraction(save_to_dir, test_dataloader)<br>           print(f<span class="hljs-string">'saving embedding'</span>)<br>           print(f<span class="hljs-string">'save_to_dir to &#123;save_to_dir&#125;'</span>)<br>       print(f<span class="hljs-string">'total time is &#123;(time.time() - t0) / 60&#125;'</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>NeuralNetwork</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NeuralNetwork</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在Nvidia TX2(arm)上搭建YOLOv4环境</title>
    <link href="/2021/04/30/2021-04-30-%E5%9C%A8Nvidia%20TX2(arm)%E4%B8%8A%E6%90%AD%E5%BB%BAYOLOv4%E7%8E%AF%E5%A2%83/"/>
    <url>/2021/04/30/2021-04-30-%E5%9C%A8Nvidia%20TX2(arm)%E4%B8%8A%E6%90%AD%E5%BB%BAYOLOv4%E7%8E%AF%E5%A2%83/</url>
    
    <content type="html"><![CDATA[<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>结合之前的经验，总共耗时两天。由于我的TX2系统为3.x版本，没有自带cuda，要安装非常麻烦，所以进行刷机。如果自带cuda请略过这一部。</p><p>主要问题集中在Jetpack系统的刷入以及Pytorch cuda加速上。</p><h2 id="安装Jetpack"><a href="#安装Jetpack" class="headerlink" title="安装Jetpack"></a>安装Jetpack</h2><h3 id="正常流程"><a href="#正常流程" class="headerlink" title="正常流程"></a>正常流程</h3><p>按照网上的教程：</p><ol><li>注册Nvidia账号</li><li>安装VMware虚拟机安装Ubuntu系统，开启桥接模式连接网络，安装sdkmanger。</li><li>按照流程打开sdkmanger下载安装。</li><li>中途提示安装，按照晚上的教程进行恢复模式。</li><li>刷入后，需要先安装ssh工具，请自行查阅。</li><li>安装ssh后，在host端继续安装cuda等工具。</li><li>成功安装。</li></ol><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul><li>如果usb和tx2的corp无法显示在虚拟机中，请打开usb3.0兼容。</li><li>sdkmanger登录以及下载几乎都需要fq，请打开sdkmanger的内置proxy设置代理(找到宿主机host的ip，以及ssr开放的端口，使用http和https)。</li><li>线材用盒子自带的usb即可。</li><li>空间需要50g以上。</li></ul><h2 id="安装Pytorch以及Torchvision"><a href="#安装Pytorch以及Torchvision" class="headerlink" title="安装Pytorch以及Torchvision"></a>安装Pytorch以及Torchvision</h2><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>最好是用Miniforge或者其他Conda环境来构建虚拟环境。</p><h3 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h3><p>踩过许多坑，最终发现以下配合最为简洁。</p><p><a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-8-0-now-available/72048" target="_blank" rel="noopener">Pytorch下载地址</a>,最好使用该地址下Nvidia官方编译好的带cuda的Pytorch，否则不能开启cuda加速。</p><p><a href="https://github.com/KumaTea/pytorch-aarch64/releases" target="_blank" rel="noopener">Torchvision下载地址</a>前者Nvidia官方只提供了本地编译torchvision，我实测编译失败且慢，不使用。(想要编译0.9.0版本的除外，见注意事项3)</p><h2 id="注意事项-1"><a href="#注意事项-1" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li>需要注意的Jetpack自带的cuda10.2的话，可以使用的pytorch版本为1.6.0及以上</li><li>如果遇到mish-cuda找不到，请<code>pip install git+https://github.com/thomasbrandon/mish-cuda/</code></li><li>实测Pytorch1.8.0+torchvision0.9.0以下的版本在使用torchvision的nms算子的时候会报错，无解。</li><li>如果出现核心已转储的问题考虑安装<code>numpy==1.19.4</code></li></ul>]]></content>
    
    
    <categories>
      
      <category>嵌入式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>arm 环境部署</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Knowledge Distillation</title>
    <link href="/2021/03/08/2021-03-08-Knowledge-Distillation/"/>
    <url>/2021/03/08/2021-03-08-Knowledge-Distillation/</url>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>经过两天的知识总结与代码梳理，终于完成了知识蒸馏相关内容的PyTorch实现。主要难度点在于：由于需要进行大量的精度验证，因此必须要实现模型精度验证的自动化，根据Hinton的论文，知识蒸馏相关的代码部分并不多。</p><h2 id="Implement"><a href="#Implement" class="headerlink" title="Implement"></a>Implement</h2><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>数据统一使用CIFAR10，后续可以进行CIFAR100数据集的实验。</p><p>使用torchvision自带的dataset类进行调用，然后进行数据增强、归一化和向量化。</p><h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><p>我们的学生网络最开始使用传统的LeNet-5 CNN网络，在训练CIFAR10的过程中，我发现精度只有不到80%，分析其网络深度不够，不足以拟合CIFAR10数据集。于是加深网络到32、64、128个卷积核，最终可以实现86%的精度。</p><p>我们教师网络采用比较熟悉的DenseNet，版本为growth=12和Depth=100的DenseNet-BC。最终训练精度为94.7%，距离论文提到的95.5%仍有一定差距。</p><h3 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h3><p>关于模型蒸馏实验的方法主要分为以下几个步骤：</p><ol><li>首先训练基本的CNN作为BaseLine。</li><li>然后训练300个epoch的DenseNet作为Teacher model。</li><li>最后使用训练好的DenseNet模型来进行推理得到一个样本后，将t-model和s-model的softmaxT结果进行KL散度拟合，加上s-model和True Label的交叉熵，形成此次推理的Loss Function。</li></ol><h3 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h3><p>本篇使用的损失函数分别是出自Hinton的<a href="https://arxiv.org/pdf/1503.02531.pdf" target="_blank" rel="noopener">Distilling the Knowledge in a Neural Network</a>和<a href="https://arxiv.org/pdf/1412.6550.pdf" target="_blank" rel="noopener">FITNETS: HINTS FORTHINDEEPNETS</a>。</p><p>具体实现代码为：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs undefined">def loss_fn_kd(outputs, labels, teacher_outputs, params):<br>    alpha = params.alpha<br>    <span class="hljs-literal">T</span> = params.temperature<br>    KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/<span class="hljs-literal">T</span>, dim=<span class="hljs-number">1</span>),<br>                             F.softmax(teacher_outputs/<span class="hljs-literal">T</span>, dim=<span class="hljs-number">1</span>)) * (alpha * <span class="hljs-literal">T</span> * <span class="hljs-literal">T</span>) + \<br>              F.cross_entropy(outputs, labels) * (<span class="hljs-number">1.</span> - alpha)<br><br>    <span class="hljs-keyword">return</span> KD_loss<br></code></pre></td></tr></table></figure><p>由于PyTorch内置的交叉熵函数只提供(output, target)输入，其中target并不是one-shot编码，KD loss需要softmax/T，故代码作者使用KL散度来代替Loss实现，由于<code>相对熵KL=-熵+交叉熵</code>，而熵又是常量，所以结果理论上应该一致。但是实际上还有另外一种基础实现：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs undefined">def loss_fn_kd_sp(outputs, labels, teacher_outputs, params):<br>    <span class="hljs-attr">alpha</span> = params.alpha<br>    <span class="hljs-attr">T</span> = params.temperature<br>    <span class="hljs-attr">soft_target</span> = F.softmax(teacher_outputs / T, <span class="hljs-attr">dim=1)</span><br>    <span class="hljs-attr">soft</span> = F.log_softmax(outputs / T, <span class="hljs-attr">dim=1)</span><br><br>    <span class="hljs-attr">soft_loss</span> = -torch.mean(torch.sum(soft_target * soft, <span class="hljs-attr">dim=1))</span><br>    <span class="hljs-attr">hard_loss</span> = F.cross_entropy(outputs, labels)<br><br>    <span class="hljs-attr">loss</span> = soft_loss * T * T * alpha + hard_loss * (<span class="hljs-number">1</span>. - alpha)<br><br>    return loss<br></code></pre></td></tr></table></figure><p>注意精度实现有一定差异，待考察。</p><h3 id="Comments"><a href="#Comments" class="headerlink" title="Comments"></a>Comments</h3><ul><li>需要关注一下Relational Network Knowledge Distillation。</li><li>根据在知乎看到的一些内容，相同的网络结构可以取得更好的效果，后续将进行尝试。</li></ul><h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p><a href="https://github.com/zhaoyiming/knowledge-distillation" target="_blank" rel="noopener">https://github.com/zhaoyiming/knowledge-distillation</a></p><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><table><thead><tr><th>TimeLine</th><th>student net</th><th>student acc</th><th>teacher net</th><th>teacher acc</th><th>kd acc</th><th>loss function</th><th>epoch</th><th>Comments</th></tr></thead><tbody><tr><td>2021.3.8.11</td><td>CNN</td><td>0.7511</td><td>DenseNet</td><td>0.8194</td><td>0.7511</td><td>fitnet</td><td>30</td><td>Inital version</td></tr><tr><td>2021.3.8.13</td><td>CNN</td><td>0.8412</td><td>DenseNet</td><td>0.9273</td><td>0.8600</td><td>fitnet</td><td>30</td><td>common version, overfit DenseNet</td></tr><tr><td>2021.3.9.09</td><td>CNN</td><td>0.8412</td><td>DenseNet</td><td>0.9470</td><td>0.8667</td><td>fitnet</td><td>30</td><td>common DenseNet</td></tr><tr><td><strong>2021.3.9.10</strong></td><td><strong>CNN</strong></td><td><strong>0.8412</strong></td><td><strong>DenseNet</strong></td><td><strong>0.9470</strong></td><td><strong>0.8831</strong></td><td><strong>softmaxT</strong></td><td><strong>100</strong></td><td><strong>softmaxT loss function</strong></td></tr><tr><td>2021.3.9.15</td><td>CNN</td><td>0.8412</td><td>DenseNet</td><td>0.9470</td><td>0.8805</td><td>fitnet</td><td>100</td><td>enlarge epoch number</td></tr><tr><td><strong>2021.3.9.17</strong></td><td><strong>CNN</strong></td><td><strong>0.8650</strong></td><td><strong>DenseNet</strong></td><td><strong>0.9470</strong></td><td><strong>0.8841</strong></td><td><strong>fitnet</strong></td><td><strong>100</strong></td><td><strong>improve CNN acc</strong></td></tr><tr><td>2021.3.9.18</td><td>CNN</td><td>0.8650</td><td>DenseNet</td><td>0.9470</td><td>0.8754</td><td>fitnet</td><td>100</td><td>change T from 20 to 4</td></tr><tr><td>2021.3.12.10</td><td>CNN</td><td>0.8650</td><td>DenseNet</td><td>0.9470</td><td>0.8854</td><td>fitnet</td><td>100</td><td>sp loss implement</td></tr><tr><td>2021.3.12.12</td><td>CNN</td><td>0.8650</td><td>DenseNet</td><td>0.9470</td><td>0.8772</td><td>softmaxT</td><td>100</td><td>sp loss implement</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>NeuralNetwork</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NeuralNetwork</tag>
      
      <tag>模型压缩</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>重温PyTorch解决Custom dataset问题</title>
    <link href="/2021/03/06/2021-03-06-%E9%87%8D%E6%B8%A9Pytorch%E8%A7%A3%E5%86%B3Custom%E6%95%B0%E6%8D%AE%E9%9B%86%E9%97%AE%E9%A2%98/"/>
    <url>/2021/03/06/2021-03-06-%E9%87%8D%E6%B8%A9Pytorch%E8%A7%A3%E5%86%B3Custom%E6%95%B0%E6%8D%AE%E9%9B%86%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h3 id="主要问题"><a href="#主要问题" class="headerlink" title="主要问题"></a>主要问题</h3><ul><li>如何解决自定义数据集构造和读取</li><li>如何将整个数据集分成训练数据和测试数据</li></ul><h3 id="PyTorch数据读取"><a href="#PyTorch数据读取" class="headerlink" title="PyTorch数据读取"></a>PyTorch数据读取</h3><p>PyTorch的数据加载模块，一共涉及到Dataset，Sampler，DataLoader三个类</p><p>三者的关系：</p><ol><li>设置Dataset，将数据data source包装成Dataset类，暴露提取接口。</li><li>设置Sampler，决定采样方式。我们是能从Dataset中提取元素了，还是需要设置Sampler告诉程序提取Dataset的策略。</li><li>将设置好的Dataset和Sampler传入DataLoader，同时可以设置shuffle，batch_size等参数。使用DataLoader对象可以快捷方便地在给定数据集上遍历。</li></ol><p>总结来说，即Dataloader负责总的调度，命令Sampler定义遍历索引的方式，然后用索引去Dataset中提取元素。于是就实现了对给定数据集的遍历。</p><p> 在本文中，我们使用自定义的Dataset，不使用Sampler。</p><h3 id="如何解决自定义数据集的构造和读取"><a href="#如何解决自定义数据集的构造和读取" class="headerlink" title="如何解决自定义数据集的构造和读取"></a>如何解决自定义数据集的构造和读取</h3><p>关于这个问题，我们一般使用神经网络框架内置的数据集，非常方便地就可以获得构造的数据集，这里以PyTorch为例，可以使用<code>trainset = torchvision.datasets.CIFAR10(root=&#39;data/&#39;,train = True,download=True)</code>来获得torchvision内置的数据集，然后再通过DataLoader进行数据读取。</p><p>当我们使用自己的数据集时，我们的文件结构一般是按数据类别进行文件分类，所以我们需要读取所有的数据到集合中，然后再根据PyTorch提供的数据集构造函数来构造一个自定义Dataset类。</p><p>一个标准的Dataset类应该是：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyDataset</span>(<span class="hljs-title">torch</span>.<span class="hljs-title">utils</span>.<span class="hljs-title">data</span>.<span class="hljs-title">Dataset</span>):<span class="hljs-comment">#需要继承torch.utils.data.Dataset</span></span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>)</span></span>:<br>        <span class="hljs-comment"># 初始化文件路径或文件名列表。</span><br>        <span class="hljs-comment"># 初始化该类的一些基本参数。</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, index)</span></span>:<br>        ＃<span class="hljs-number">1</span>。从文件中读取一个数据（例如，plt.imread）。<br>        ＃<span class="hljs-number">2</span>。预处理数据（例如torchvision.Transform）。<br>        ＃<span class="hljs-number">3</span>。返回单个数据对（例如图像和标签）。<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>)</span></span>:<br>        <span class="hljs-comment"># 返回数据集的总大小。</span><br></code></pre></td></tr></table></figure><p>我们构造的Dataset：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NotMinstDataset</span>(<span class="hljs-title">Dataset</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, file_dir)</span></span>:<br>        <span class="hljs-keyword">self</span>.imgs = []<br>        labels = []<br>        <span class="hljs-comment"># 从所有的文件夹中读取图片</span><br>        <span class="hljs-keyword">for</span> root, sub_folders, files <span class="hljs-keyword">in</span> os.walk(file_dir):<br>            <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> <span class="hljs-symbol">files:</span><br>                <span class="hljs-keyword">self</span>.imgs.append(os.path.join(root, name))<br>                labels.append(root.split(<span class="hljs-string">"\\"</span>)[<span class="hljs-number">1</span>])<br>                <br>        <span class="hljs-comment"># 将String类型的标签向量化</span><br>        le = preprocessing.LabelEncoder()<br>        <span class="hljs-comment"># 变成array</span><br>        <span class="hljs-keyword">self</span>.targets = le.fit_transform(labels)<br>        <span class="hljs-comment"># 变为tensor</span><br>        <span class="hljs-keyword">self</span>.targets = torch.as_tensor(<span class="hljs-keyword">self</span>.targets)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, index)</span></span>:<br>        img = <span class="hljs-keyword">self</span>.imgs[index]<br>        label = <span class="hljs-keyword">self</span>.targets[index]<br>        <span class="hljs-comment"># 读取图片并转换为向量</span><br>        img = Image.open(img)<br>        img = <span class="hljs-keyword">self</span>.img_transform(img)<br><br>        <span class="hljs-keyword">return</span> img, label<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>)</span></span>:<br>        <span class="hljs-keyword">return</span> len(<span class="hljs-keyword">self</span>.imgs)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">img_transform</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, img)</span></span>:<br>        transform = transforms.Compose(<br>            [<br>                transforms.ToTensor(),<br>            ]<br>        )<br>        img = transform(img)<br>        <span class="hljs-keyword">return</span> img<br></code></pre></td></tr></table></figure><p>构造Dataset类后，我们直接使用Dataloader进行读取:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs undefined">def data(<span class="hljs-attribute">train</span>=<span class="hljs-literal">True</span>):<br>    dataset = NotMinstDataset(<span class="hljs-string">"./notMNIST_small"</span>)<br>    train_size = int(0.8 * len(dataset))<br>    test_size = len(dataset) - train_size<br>    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])<br>    <span class="hljs-keyword">if</span> train:<br>        loader = DataLoader(train_dataset, <span class="hljs-attribute">batch_size</span>=64, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">else</span>:<br>        loader = DataLoader(test_dataset, <span class="hljs-attribute">batch_size</span>=64, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">True</span>)<br>    return loader<br></code></pre></td></tr></table></figure><p><a href="https://zhuanlan.zhihu.com/p/270028097" target="_blank" rel="noopener">参考知乎链接</a></p><h3 id="如何将整个数据集分成训练数据和测试数据"><a href="#如何将整个数据集分成训练数据和测试数据" class="headerlink" title="如何将整个数据集分成训练数据和测试数据"></a>如何将整个数据集分成训练数据和测试数据</h3><p>思考，一般的数据集都会帮你划分好训练集和测试集，但是当你自己使用自定义数据集的时候，可能就需要自己进行分割。在哪一步对数据集进行划分是一个问题，以往我一般在构造Dataset类的准备函数中使用<code>sklearn.model_selection</code>的<code>train_test_split</code>函数进行数据集的划分，这样当我们使用dataloader进行数据集调用的时候，很可能遇到函数复用时实例化了两个分割的数据集。于是乎使用以下方法可以避免以上的问题。但是同时这个方法仍有问题，在每类样本不均衡的时候，很可能会造成抽样不均衡。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs undefined">def data(<span class="hljs-attribute">train</span>=<span class="hljs-literal">True</span>):<br>    dataset = NotMinstDataset(<span class="hljs-string">"./notMNIST_small"</span>)<br>    train_size = int(0.8 * len(dataset))<br>    test_size = len(dataset) - train_size<br>    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])<br>    <span class="hljs-keyword">if</span> train:<br>        loader = DataLoader(train_dataset, <span class="hljs-attribute">batch_size</span>=64, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">else</span>:<br>        loader = DataLoader(test_dataset, <span class="hljs-attribute">batch_size</span>=64, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">True</span>)<br>    return loader<br></code></pre></td></tr></table></figure><p><a href="https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets" target="_blank" rel="noopener">参考StackOverflow</a></p><h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> time<br><br>device = torch.device(<span class="hljs-string">"cuda:0"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)<br>print(<span class="hljs-string">"device:"</span>, device)<br><br><br><span class="hljs-comment"># Dataset</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NotMinstDataset</span><span class="hljs-params">(Dataset)</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, file_dir)</span>:</span><br>        self.imgs = []<br>        labels = []<br>        <span class="hljs-keyword">for</span> root, sub_folders, files <span class="hljs-keyword">in</span> os.walk(file_dir):<br>            <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> files:<br>                self.imgs.append(os.path.join(root, name))<br>                labels.append(root.split(<span class="hljs-string">"\\"</span>)[<span class="hljs-number">1</span>])<br>        le = preprocessing.LabelEncoder()<br>        self.targets = le.fit_transform(labels)<br>        self.targets = torch.as_tensor(self.targets)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(self, index)</span>:</span><br>        img = self.imgs[index]<br>        label = self.targets[index]<br>        img = Image.open(img)<br>        img = self.img_transform(img)<br><br>        <span class="hljs-keyword">return</span> img, label<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span><br>        <span class="hljs-keyword">return</span> len(self.imgs)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">img_transform</span><span class="hljs-params">(self, img)</span>:</span><br>        transform = transforms.Compose(<br>            [<br>                transforms.ToTensor(),<br>            ]<br>        )<br>        img = transform(img)<br>        <span class="hljs-keyword">return</span> img<br><br><br><span class="hljs-comment"># getdata</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">data</span><span class="hljs-params">(train=True)</span>:</span><br>    dataset = NotMinstDataset(<span class="hljs-string">"./notMNIST_small"</span>)<br>    train_size = int(<span class="hljs-number">0.8</span> * len(dataset))<br>    test_size = len(dataset) - train_size<br>    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])<br>    <span class="hljs-keyword">if</span> train:<br>        loader = DataLoader(train_dataset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-keyword">True</span>)<br>    <span class="hljs-keyword">else</span>:<br>        loader = DataLoader(test_dataset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-keyword">True</span>)<br>    <span class="hljs-keyword">return</span> loader<br><br><br><span class="hljs-comment"># Network</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Net</span><span class="hljs-params">(nn.Module)</span>:</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span><br>        super(Net, self).__init__()<br><br>        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, padding=<span class="hljs-number">2</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>)<br><br>        self.fc1 = nn.Linear(<span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>, <span class="hljs-number">120</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)<br>        self.fc3 = nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span><br>        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>        x = F.max_pool2d(F.relu(self.conv2(x)), (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>        x = x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)<br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br>        x = self.fc3(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><br>net = Net().to(device)<br>criterion = nn.CrossEntropyLoss().to(device)<br>optimizer = optim.Adam(net.parameters(), lr=<span class="hljs-number">0.001</span>)<br><br>trainloader = data(<span class="hljs-keyword">True</span>)<br>testloader = data(<span class="hljs-keyword">False</span>)<br>t0 = time.time()<br><span class="hljs-comment"># training</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>):<br>    running_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> batch_idx, (input, label) <span class="hljs-keyword">in</span> enumerate(trainloader):<br>        input, label = input.to(device), label.to(device).squeeze()<br>        optimizer.zero_grad()<br>        output = net(input)<br>        loss = criterion(output, label)<br>        loss.backward()<br>        optimizer.step()<br><br>        running_loss += loss.item()<br><br>        <span class="hljs-keyword">if</span> batch_idx % <span class="hljs-number">100</span> == <span class="hljs-number">99</span>:<br>            print(<span class="hljs-string">'[%d, %5d] loss: %.10f'</span> % (epoch + <span class="hljs-number">1</span>, batch_idx + <span class="hljs-number">1</span>, running_loss / <span class="hljs-number">100</span>))<br>            running_loss = <span class="hljs-number">0.0</span><br>print(<span class="hljs-string">'&#123;&#125; seconds'</span>.format(time.time() - t0))<br><br><span class="hljs-comment"># 测试</span><br>correct = <span class="hljs-number">0</span><br>total = <span class="hljs-number">0</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> batch_idx, (input, label) <span class="hljs-keyword">in</span> enumerate(testloader):<br>        input, label = input.to(device), label.to(device)<br>        outputs = net(input)<br>        _, predicted = torch.max(outputs.data, <span class="hljs-number">1</span>)<br>        total += label.size(<span class="hljs-number">0</span>)<br>        correct += (predicted == label).sum().item()<br><br>print(<span class="hljs-string">'Accuracy of the network on the test images: %.10f %%'</span> % (<span class="hljs-number">100</span> * correct / total))<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>NeuralNetwork</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NeuralNetwork</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>腾讯犀牛鸟面试小记</title>
    <link href="/2021/03/05/2021-03-05-%E8%85%BE%E8%AE%AF%E7%8A%80%E7%89%9B%E9%B8%9F%E9%9D%A2%E8%AF%95%E5%B0%8F%E8%AE%B0/"/>
    <url>/2021/03/05/2021-03-05-%E8%85%BE%E8%AE%AF%E7%8A%80%E7%89%9B%E9%B8%9F%E9%9D%A2%E8%AF%95%E5%B0%8F%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="面试准备"><a href="#面试准备" class="headerlink" title="面试准备"></a>面试准备</h1><h3 id="自我介绍"><a href="#自我介绍" class="headerlink" title="自我介绍"></a>自我介绍</h3><p>我叫赵一鸣，是来自南京航空航天大学的研一的学生，平时比较热爱互联网技术，本科主要学习的软件开发，擅长安卓开发。掌握C、Java以及Python语言，可以自己搭建服务器以及网站前后端，对部署嵌入式设备深度学习环境比较熟练。</p><h3 id="研究方向及亮点介绍"><a href="#研究方向及亮点介绍" class="headerlink" title="研究方向及亮点介绍"></a>研究方向及亮点介绍</h3><p>我目前在做的研究方向主要集中在移动设备多模态的智能感知技术，具体到在做的东西主要是基于超声波的手势识别，毕业论文基于元学习的超声波手势识别系统，研一上学期主要在进行嵌入式设备的神经网络开发，目前正在准备结合声波物理模型和深度学习模型对移动端声波手势识别进行模型压缩，主要是teacher-student网络。</p><p>我比较擅长嵌入式设备的工程实践，可以熟练地使用树莓派和Nvidia的Tx2开发板交叉编译神经网络库以及配置深度学习环境。可以在实践中来对嵌入式设备模式识别进行创新改进。</p><h3 id="个人研究方向与申报课题的相关性"><a href="#个人研究方向与申报课题的相关性" class="headerlink" title="个人研究方向与申报课题的相关性"></a>个人研究方向与申报课题的相关性</h3><p>我个人研究方向主要集中在移动设备的智能感知领域，已经做的工作主要是关于(智能手机、VR/AR之类的)商业移动设备的超声波手势识别，由于使用神经网络要求算力高，数据量大，声波手势识别会耗费大量的计算资源，要想在实际移动设备部署中获得优秀的效能，一定绕不开模型压缩。 所以我想结合本领域内容和模型压缩来继续我的研究工作，在无线网络顶刊中知识蒸馏方法经常出现。</p><h3 id="你的深度学习研究项目"><a href="#你的深度学习研究项目" class="headerlink" title="你的深度学习研究项目"></a>你的深度学习研究项目</h3><p>我参与过的深度学习项目主要是基于元学习的超声波手势识别系统和一个战场识别系统。</p><ul><li>超声波识别系统是我的本科毕业论文，主要是借助商业手机扬声器发出超声波，麦克风接受超声波信号，然后通过一个特别设计的孪生网络对测试样本和支持集样本提取特征，最后通过一个特别的深度关系网络评估相似度得到测试样本标签，训练方法使用一种基于metric learning元学习的特定方法，通过将训练集划分为测试样本和支持样本直接模拟推理过程增加泛化性能。</li><li>战场识别系统主要使用yolov4结合多模态来进行一些战场物体的识别，我主要负责的是模型的推理以及在一台arm架构的设备上进行模型部署，由于使用的嵌入式设备只支持C++动态库，所以我负责处理推理代码的C++实现，编译一些必要的神经网络库，编译代码实现，构建前后端系统。</li><li>简单介绍元学习：元学习，也可以叫做学习去学习，区别于深度学习这种通过训练数据学习输入到输出之间的映射关系，优化损失函数来进行优化参数，元学习通过大量训练和目标任务相似的任务来训练一个元学习器，从而实现只需要极少样本就可以实现模型训练。</li></ul><h1 id="其他准备"><a href="#其他准备" class="headerlink" title="其他准备"></a>其他准备</h1><h3 id="深度学习的特点"><a href="#深度学习的特点" class="headerlink" title="深度学习的特点"></a>深度学习的特点</h3><ul><li>局部连接</li><li>权值共享</li><li>池化操作</li><li>多层次结构</li></ul><h3 id="深度学习中的超参数"><a href="#深度学习中的超参数" class="headerlink" title="深度学习中的超参数"></a>深度学习中的超参数</h3><ul><li>正则化参数<ul><li>L1 L2</li></ul></li><li>网络结构<ul><li>各层size</li></ul></li><li>优化参数<ul><li>LR</li><li>Batch Size</li><li>Dropout</li><li>优化器</li></ul></li></ul><h3 id="模型压缩"><a href="#模型压缩" class="headerlink" title="模型压缩"></a>模型压缩</h3><ul><li><p>剪枝</p><p>NAS</p></li><li><p>量化</p><p>int8 int4 二值</p></li><li><p>知识蒸馏 </p><p>TS网络</p></li><li><p>轻量化模型</p></li></ul><h3 id="一些深度学习面试问题"><a href="#一些深度学习面试问题" class="headerlink" title="一些深度学习面试问题"></a>一些深度学习面试问题</h3><ul><li><p>线性回归和逻辑回归区别联系</p><ul><li>都为线性模型</li><li>线性回归解决回归任务，逻辑回归解决分类任务</li><li>线性回归进行线性预测，逻辑回归在线性回归的基础上增加sigmoid函数对预测结果进行分类</li></ul></li><li><p>性能评估</p><ul><li>查准率</li><li>查全率</li></ul></li><li><p>dropout作用</p><p>在网络训练时，在全连接层随机丢弃一些神经元，使隐层神经元不会太依赖局部特征，防止过拟合。</p></li><li><p>不同损失函数特点差异</p><ul><li>cross-entropy</li><li>MSE</li></ul></li><li><p>权重初始化方法特点</p><ul><li>Goss</li><li>Uniform</li><li>Xavier</li><li>kaiming</li></ul></li><li><p>Bagging and boosting</p><ul><li><p>bagging </p><p>从原始数据随机挑选数据训练k个分类器，然后对预测值投票决定。</p></li></ul></li><li><p>K折交叉验证</p><p>将所有训练数据分为k份，将k-1份作为训练数据，余下1份作为测试数据，直到所有数据都被测试后，将结果加权平均</p></li><li><p>梯度爆炸和梯度消失</p><ul><li>从网络阶段来说，网络层数太多，而卷积神经网络的反向梯度更新过程又需要大量的(损失函数对第一层权重求导需要从最后一层开始链式原则相乘)乘积计算，出现过小的值会导致梯度消失，出现过大的值则会导致梯度爆炸。</li><li>从激活函数来说，sigmoid函数的特性导致(或者说sigmoid函数将函数的映射挤压在一个小范围内)，数据在极大或极小的情况下，梯度的变化率很小，导致梯度消失。使用relu函数即可解决问题。</li></ul></li><li><p>loss不变化原因以及解决方案</p><p>可能是梯度消失，建议改变权重初始化或者改变激活函数。</p></li><li><p>为什么使用尺寸更小的卷积核</p><p>在相同激活野的情况下拥有更少的参数，防止过拟合，减少网络结构。</p></li></ul><h1 id="面试总结"><a href="#面试总结" class="headerlink" title="面试总结"></a>面试总结</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">完全没有问到模型压缩和深度学习的知识。<br>问的问题主要集中在：<br></code></pre></td></tr></table></figure><h3 id="元学习"><a href="#元学习" class="headerlink" title="元学习"></a>元学习</h3><ul><li><p>元学习训练过程</p></li><li><p>元学习原理</p></li><li><p>具体PyTorch实现的一些代码</p></li></ul><h3 id="信号处理"><a href="#信号处理" class="headerlink" title="信号处理"></a>信号处理</h3><ul><li><p>手机发射收集信号的过程原理</p></li><li><p>I、Q为什么能提取特征？</p></li></ul><h3 id="安卓"><a href="#安卓" class="headerlink" title="安卓"></a>安卓</h3><ul><li><p>子线程更新主线程UI的方法</p></li><li><p>网络编程是否擅长</p></li><li><p>对相机编程有没有了解</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>工作实习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在树莓派上运行YOLO-v4</title>
    <link href="/2021/02/13/2021-02-13-%E5%9C%A8%E6%A0%91%E8%8E%93%E6%B4%BE%E4%B8%8A%E8%BF%90%E8%A1%8Cyolo-v4/"/>
    <url>/2021/02/13/2021-02-13-%E5%9C%A8%E6%A0%91%E8%8E%93%E6%B4%BE%E4%B8%8A%E8%BF%90%E8%A1%8Cyolo-v4/</url>
    
    <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>需要在树莓派上完成调用YOLO-v4并且尽量减少推理时间的任务。</p><p>大部分时间在尝试如何在树莓派上运行基于PyTorch的YOLO-v4，最终使用基于OpenCV-Python调用YOLO-v4可行，推理时间4s左右。</p><p>OpenCV有加速库，所以比基于darknet的YOLO-v4推理速度更快一些，而基于OpenCV编译的darknet并没有加速，需要再实验论证。</p><h2 id="环境-amp-准备"><a href="#环境-amp-准备" class="headerlink" title="环境&amp;准备"></a>环境&amp;准备</h2><p>为最大化树莓派效能，我们为树莓派刷入了Ubuntu 20.04 Server的基于arm64的系统。由于特殊原因，我们也使用了Ubuntu官网提供的Ubuntu 18.04 Desktop系统。</p><p>为了效率和方便，我们使用pip安装我们的深度学习环境，为了提升速度我们首先<a href="https://zhaoyiming.github.io/2021/02/13/Speed%20up%20your%20runtime%20environment%20Deployment%20of%20arm-based%20devices/">替换系统中的apt源和使用国内的pip源</a>。又为了避免破坏系统环境的python，我们一般使用anaconda来管理深度学习环境。由于基于arm64的anaconda还没有发行，我们使用<a href="https://github.com/conda-forge/miniforge/" target="_blank" rel="noopener">Miniforge</a>来替代。直接下载bash安装后切换用户即可。</p><p>PyTorch相关第三方包<a href="https://github.com/KumaTea/pytorch-aarch64/releases" target="_blank" rel="noopener">Here</a>。</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="基于PyTorch的YOLO-v4"><a href="#基于PyTorch的YOLO-v4" class="headerlink" title="基于PyTorch的YOLO-v4"></a>基于PyTorch的YOLO-v4</h3><p>在Github中搜索YOLO-v4，down下几个Top基于PyTorch实现的YOLO-v4库。然而，我发现这些基于PyTorch的YOLO-v4在推理照片的时候无法正常运行，所有数据都是错误的。我怀疑是树莓派内存太小导致模型无法正常加载，所以尝试使用darknet实现YOLO-v4。</p><p>在后来的实验中，我们同样验证了相同的结果，使用基于PyTorch的YOLO-v4-tiny是可以正常运行，但仍比基于darknet的YOLO-v4-tiny推理要慢。</p><h3 id="基于Darknet的YOLO-v4"><a href="#基于Darknet的YOLO-v4" class="headerlink" title="基于Darknet的YOLO-v4"></a>基于Darknet的YOLO-v4</h3><p>从Github上down下来官方的darknet库，按照要求解压进入文件夹进行<code>make -j8</code>编译，结果发现并不能正常编译，原来是Ubuntu20.10系统的g++版本太高，导致无法正常进行编译，所以我们使用Ubuntu18.04系统继续进行编译，编译可以正常通过。需要注意的是，如果考虑是否与OpenCV一起编译，请修改Makefile文件。若compile with OpenCV，请<code>apt install libOpenCV-dev</code>。</p><p>基于Darknet的YOLO-v4的推理耗时在58s左右，YOLO-v4-tiny的推理时间在2s左右，这个数据并不能令我们满意，而且由于要使用flask，我们只得又使用Ubuntu20.10系统寻求新的方法。</p><h3 id="基于OpenCV-python的YOLO-v4"><a href="#基于OpenCV-python的YOLO-v4" class="headerlink" title="基于OpenCV-python的YOLO-v4"></a>基于OpenCV-python的YOLO-v4</h3><p>我们知道OpenCV4已经内置了YOLO-v4的调用，所以我们使用<code>pip install OpenCV-python==4.4.0</code>，使用内置函数进行调用，可以正常使用，YOLO-v4推理时间为4s左右，YOLO-v4-tiny为0.4s左右，it is over。简单调用一个代码：</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs undefined">import cv2 as <span class="hljs-built_in">cv</span><br>import <span class="hljs-built_in">time</span><br>import os<br><br>basedir = os.path.abspath(os.path.dirname(__file__))<br>index = basedir.rfind('/')<br>basedir = basedir[:index]<br>model_dir=basedir+'/ming_net/'<br><br>def uav_detect(img_name, img):<br>    net = <span class="hljs-built_in">cv</span>.dnn_DetectionModel(model_dir+'YOLO-v4.cfg', model_dir+'YOLO-v4.weights')<br>    net.setInputSize(<span class="hljs-number">320</span>, <span class="hljs-number">320</span>)<br>    net.setInputScale(<span class="hljs-number">1.0</span> / <span class="hljs-number">255</span>)<br>    net.setInputSwapRB(True)<br>    frame = <span class="hljs-built_in">cv</span>.imread(img)<br>    with open(model_dir+'coco.names', 'rt') as f:<br>        names = f.<span class="hljs-built_in">read</span>().rstrip('\n').<span class="hljs-built_in">split</span>('\n')<br>    startTime = <span class="hljs-built_in">time</span>.<span class="hljs-built_in">time</span>()<br>    classes, confidences, boxes = net.detect(frame, confThreshold=<span class="hljs-number">0.1</span>, nmsThreshold=<span class="hljs-number">0.4</span>)<br>    endTime = <span class="hljs-built_in">time</span>.<span class="hljs-built_in">time</span>()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"Time: &#123;&#125;s"</span>.format(endTime - startTime))<br><br>    <span class="hljs-keyword">for</span> classId, confidence, <span class="hljs-built_in">box</span> <span class="hljs-keyword">in</span> zip(classes.<span class="hljs-built_in">flatten</span>(), confidences.<span class="hljs-built_in">flatten</span>(), boxes):<br>        <span class="hljs-keyword">if</span> classId==<span class="hljs-number">0</span>:<br>            coordinates = []<br>            boxes_item_package = &#123;&#125;<br>            <span class="hljs-built_in">label</span> = '<span class="hljs-symbol">%</span>.2f' <span class="hljs-symbol">%</span> confidence<br>            <span class="hljs-built_in">label</span> = '<span class="hljs-built_in">%s</span>: <span class="hljs-built_in">%s</span>' <span class="hljs-symbol">%</span> (names[classId], <span class="hljs-built_in">label</span>)<br>            labelSize, baseLine = <span class="hljs-built_in">cv</span>.getTextSize(<span class="hljs-built_in">label</span>, <span class="hljs-built_in">cv</span>.FONT_HERSHEY_SIMPLEX, <span class="hljs-number">0.5</span>, <span class="hljs-number">1</span>)<br>            left, top, <span class="hljs-built_in">width</span>, <span class="hljs-built_in">height</span> = <span class="hljs-built_in">box</span><br>            top = <span class="hljs-built_in">max</span>(top, labelSize[<span class="hljs-number">1</span>])<br>            <span class="hljs-built_in">cv</span>.<span class="hljs-built_in">rectangle</span>(frame, <span class="hljs-built_in">box</span>, <span class="hljs-built_in">color</span>=(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>), thickness=<span class="hljs-number">1</span>)<br>            <span class="hljs-built_in">cv</span>.<span class="hljs-built_in">rectangle</span>(frame, (left, top - labelSize[<span class="hljs-number">1</span>]), (left + labelSize[<span class="hljs-number">0</span>], top + baseLine), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), <span class="hljs-built_in">cv</span>.FILLED)<br>            <span class="hljs-built_in">cv</span>.putText(frame, <span class="hljs-built_in">label</span>, (left, top), <span class="hljs-built_in">cv</span>.FONT_HERSHEY_SIMPLEX, <span class="hljs-number">0.5</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>))<br>    <br>    <span class="hljs-built_in">cv</span>.waitKey(<span class="hljs-number">0</span>)<br>    <span class="hljs-built_in">return</span> frame<br></code></pre></td></tr></table></figure><h3 id="基于YOLObile的尝试"><a href="#基于YOLObile的尝试" class="headerlink" title="基于YOLObile的尝试"></a>基于YOLObile的尝试</h3><p>由于我们的主要目的是最小化在树莓派这样性能羸弱的平台上推理YOLO网络的耗时，所以当我看到YOLObile宣称超越YOLO-v4-tiny时，我决定进行尝试。但是最终基于YOLO-v4推理一张图片耗时为40s。</p><p>猜想本次实验与其宣称的差异是因为树莓派没有独立GPU，而原文的对比试验是基于三星S20的GPU进行。</p><h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><ul><li>需要注意的是，为了推理速度，我们使用的所有输入尺寸都为320*320，请在各种cfg文件中修改。</li><li>在Ubuntu 20.10系统中，matplotlib是无法安装的。</li><li>在Ubuntu 18.04系统中安装一些软件会出现错误:缺少glibc2.28。因此无法使用flask，目前没有找到解决方法。</li></ul><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><table><thead><tr><th>设备/系统</th><th>backbone</th><th>置信度</th><th>耗费时间</th></tr></thead><tbody><tr><td>树莓派arm64Ubuntu 20</td><td>YOLO-v4/OpenCV</td><td>person5/0.95/0.91/0.87</td><td>3.49s</td></tr><tr><td>树莓派arm64Ubuntu 20</td><td>YOLO-v4-tiny/OpenCV</td><td>person2/0.88/0.73</td><td>0.3911s</td></tr><tr><td>树莓派arm64Ubuntu 20</td><td>YOLO-v4-custom/OpenCV</td><td>person3/0.83/0.83/0.68</td><td>3.49s</td></tr><tr><td>树莓派arm64Ubuntu 18</td><td>YOLO-v4/darknet</td><td>person6</td><td>75s</td></tr><tr><td>树莓派arm64Ubuntu 18</td><td>YOLO-v4-tiny/darknet</td><td>person2/0.88/0.73</td><td>2s</td></tr><tr><td>树莓派arm64Ubuntu 18</td><td>YOLO-v4/darknet-compiled with OpenCV</td><td>person6</td><td>75s</td></tr><tr><td>树莓派arm64Ubuntu 20</td><td>YOLO-v4-tiny/pytorch</td><td></td><td>内存溢出</td></tr><tr><td>树莓派arm64Ubuntu 20</td><td>YOLO-v4-tiny/pytorch</td><td>person2/0.88/0.73</td><td>5.68s</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>嵌入式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>arm</tag>
      
      <tag>NeuralNetwork</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Speed up your runtime environment Deployment of arm-based devices</title>
    <link href="/2021/02/13/2021-02-13-Speed-up-your-runtime-environment-Deployment-of-arm-based-devices/"/>
    <url>/2021/02/13/2021-02-13-Speed-up-your-runtime-environment-Deployment-of-arm-based-devices/</url>
    
    <content type="html"><![CDATA[<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Generally, it is not complicated to deploy the indispensable runtime environment of deep learning on arm-based devices. Unfortunately, the prior problem of deploying the environment is the awful download speed under a closed network. Here are some methods to speed up your environment deployment.</p><h3 id="Apt-sources-list"><a href="#Apt-sources-list" class="headerlink" title="Apt sources list"></a>Apt sources list</h3><p>Although we deploy the deep learning runtime environment through the python-pip package tool, however, to install python-pip and some fundamental packages on ubuntu for arm, it is necessary to modify the apt source setup.<br>First, open <code>/etc/apt/sources.list</code> and replace the text with the following content.</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs undefined"># basic software <span class="hljs-keyword">source</span> of Tsinghua university<br><span class="hljs-keyword">deb</span> http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ bionic main restricted universe multiverse<br># <span class="hljs-keyword">deb</span>-src http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ bionic main restricted universe multiverse<br><span class="hljs-keyword">deb</span> http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ bionic-updates main restricted universe multiverse<br># <span class="hljs-keyword">deb</span>-src http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ bionic-updates main restricted universe multiverse<br><span class="hljs-keyword">deb</span> http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ bionic-backports main restricted universe multiverse<br># <span class="hljs-keyword">deb</span>-src http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ bionic-backports main restricted universe multiverse<br><span class="hljs-keyword">deb</span> http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ bionic-security main restricted universe multiverse<br># <span class="hljs-keyword">deb</span>-src http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ bionic-security main restricted universe multiverse<br><br># preposed software <span class="hljs-keyword">source</span><br># <span class="hljs-keyword">deb</span> http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ bionic-proposed main restricted universe multiverse<br># <span class="hljs-keyword">deb</span>-src http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ bionic-proposed main restricted universe multiverse<br></code></pre></td></tr></table></figure><p>If you are in Ubuntu 20.10, you should place the following content:</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs undefined"># basic software <span class="hljs-keyword">source</span> of Tsinghua university<br><span class="hljs-keyword">deb</span> http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ focal main restricted universe multiverse<br># <span class="hljs-keyword">deb</span>-src http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ focal main restricted universe multiverse<br><span class="hljs-keyword">deb</span> http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ focal-updates main restricted universe multiverse<br># <span class="hljs-keyword">deb</span>-src http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ focal-updates main restricted universe multiverse<br><span class="hljs-keyword">deb</span> http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ focal-backports main restricted universe multiverse<br># <span class="hljs-keyword">deb</span>-src http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ focal-backports main restricted universe multiverse<br><span class="hljs-keyword">deb</span> http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ focal-security main restricted universe multiverse<br># <span class="hljs-keyword">deb</span>-src http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ focal-security main restricted universe multiverse<br><br># preposed software <span class="hljs-keyword">source</span><br># <span class="hljs-keyword">deb</span> http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ focal-proposed main restricted universe multiverse<br># <span class="hljs-keyword">deb</span>-src http<span class="hljs-variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/ubuntu-ports/ focal-proposed main restricted universe multiverse<br></code></pre></td></tr></table></figure><p>And you can apply the following script to replace the apt source of Huawei:</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">wget -O /etc/apt/sources.<span class="hljs-keyword">list</span> http<span class="hljs-variable">s:</span>//repo.huaweicloud.<span class="hljs-keyword">com</span>/repository/<span class="hljs-keyword">conf</span>/Ubuntu-Ports-bionic.<span class="hljs-keyword">list</span><br>apt-<span class="hljs-built_in">get</span> <span class="hljs-keyword">update</span><br></code></pre></td></tr></table></figure><h3 id="Python-pip-mirror-source"><a href="#Python-pip-mirror-source" class="headerlink" title="Python-pip mirror source"></a>Python-pip mirror source</h3><p>The simplest method is the following script:</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs undefined"># replace proper mirror <span class="hljs-keyword">source</span> with http<span class="hljs-variable">s:xxx</span><br>pip config <span class="hljs-keyword">set</span> <span class="hljs-keyword">global</span>.<span class="hljs-built_in">index</span>-url http<span class="hljs-variable">s:</span>//pypi.tuna.tsinghua.edu.<span class="hljs-keyword">cn</span>/simple<br><span class="hljs-built_in">or</span><br>pip config <span class="hljs-keyword">set</span> <span class="hljs-keyword">global</span>.<span class="hljs-built_in">index</span>-url http://pypi.douban.<span class="hljs-keyword">com</span>/simple<br><span class="hljs-built_in">or</span> use<br>pip install xxx -i http://pypi.douban.<span class="hljs-keyword">com</span>/simple --trusted-host pypi.douban.<span class="hljs-keyword">com</span><br></code></pre></td></tr></table></figure><p>Then you can apply <code>pip install xxx</code> and Enjoy it.</p>]]></content>
    
    
    <categories>
      
      <category>嵌入式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>arm</tag>
      
      <tag>环境部署</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用arm64架构物理机构建K8s(Kubernetes)集群</title>
    <link href="/2020/12/02/2020-12-02-%E4%BD%BF%E7%94%A8arm64%E6%9E%B6%E6%9E%84%E7%89%A9%E7%90%86%E6%9C%BA%E6%9E%84%E5%BB%BAK8s%E9%9B%86%E7%BE%A4/"/>
    <url>/2020/12/02/2020-12-02-%E4%BD%BF%E7%94%A8arm64%E6%9E%B6%E6%9E%84%E7%89%A9%E7%90%86%E6%9C%BA%E6%9E%84%E5%BB%BAK8s%E9%9B%86%E7%BE%A4/</url>
    
    <content type="html"><![CDATA[<p>在Windows下安装K8s集群并不算很难，在arm64系统下安装会出现很多问题，如果有代理，建议全程代理。</p><h2 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h2><p>本文使用的集群由一个Nvidia Tx2当作master节点，系统为JetPack 3.3(Ubuntu 18.04)。</p><p>三个树莓派刷成ubuntu系统作为node节点，系统具体为arm64的18.04.5的<a href="https://ubuntu.com/download/raspberry-pi" target="_blank" rel="noopener">Ubuntu Server</a>。所有物理机处于同一个局域网络环境下。</p><h2 id="安装步骤："><a href="#安装步骤：" class="headerlink" title="安装步骤："></a>安装步骤：</h2><h3 id="master篇"><a href="#master篇" class="headerlink" title="master篇"></a>master篇</h3><h4 id="关闭swap"><a href="#关闭swap" class="headerlink" title="关闭swap"></a>关闭swap</h4><p>如果不关闭swap，K8s会出现各种报错。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs undefined"># 手动关闭<span class="hljs-built_in">swap</span><br>    swapoff -a<br># 关闭<span class="hljs-built_in">swap</span>开机自启，注释掉<span class="hljs-built_in">swap</span>字样的行。不过该行可能不存在，就需要每次手动关闭<span class="hljs-built_in">swap</span>。<br>    nano /etc/fstab<br></code></pre></td></tr></table></figure><h4 id="安装kubeadm-kubectl-kubelet-docker-ce"><a href="#安装kubeadm-kubectl-kubelet-docker-ce" class="headerlink" title="安装kubeadm kubectl kubelet docker-ce"></a>安装kubeadm kubectl kubelet docker-ce</h4><p>由于我个人无法找到正确的kubernetes源来安装三个kubeadm组件，所以这里我推荐大家去清华源自的<a href="https://mirrors.tuna.tsinghua.edu.cn/kubernetes/apt/pool/" target="_blank" rel="noopener">kubernetes仓库</a>中寻找离线包进行下载安装。我们需要安装的是<a href="https://mirrors.tuna.tsinghua.edu.cn/kubernetes/apt/pool/kubectl_1.15.2-00_arm64_590728548106979631ff013af47054895222f1ab25674aed5a6e6c11460648d1.deb" target="_blank" rel="noopener">kubectl_1.15.2</a>、<a href="https://mirrors.tuna.tsinghua.edu.cn/kubernetes/apt/pool/kubelet_1.15.2-00_arm64_b3e642cecc9f8b162da843d2b125dae20415840122fa7bee396fe5eaea8cac81.deb" target="_blank" rel="noopener">kubelet_1.15.2</a>、<a href="https://mirrors.tuna.tsinghua.edu.cn/kubernetes/apt/pool/kubeadm_1.15.2-00_arm64_6808e06f1d0e6a24b04b22b701cdbeb12fb0a19c51c5948a2f7ac29c6fdefce7.deb" target="_blank" rel="noopener">kubeadm_1.15.2</a>和<a href="https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu/dists/xenial/pool/stable/arm64/docker-ce_18.06.2~ce~3-0~ubuntu_arm64.deb" target="_blank" rel="noopener">docker-ce_18.06.2</a>这四个包。下载后使用以下命令安装：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">sudo chmod +x xxx<span class="hljs-selector-class">.deb</span><br>sudo dpkg -<span class="hljs-selector-tag">i</span> xxx.deb<br></code></pre></td></tr></table></figure><p>但是在安装kubelet的过程中可能需要安装如socat之类的依赖，如果添加的源中无法找到合适的依赖，可以使用华为源，以下命令直接替换：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">wget -O /etc/apt/sources.<span class="hljs-keyword">list</span> http<span class="hljs-variable">s:</span>//repo.huaweicloud.<span class="hljs-keyword">com</span>/repository/<span class="hljs-keyword">conf</span>/Ubuntu-Ports-bionic.<span class="hljs-keyword">list</span><br>   apt-<span class="hljs-built_in">get</span> <span class="hljs-keyword">update</span><br></code></pre></td></tr></table></figure><p>或者清华源，需要执行添加到/etc/apt/sources.list文件中：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-comment"># 理论为16.04的源，但是我没能成功找到18.04的arm64的清华源地址。</span><br>    deb http:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/ubuntu-ports/</span> xenial main multiverse restricted universe<br>    deb http:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/ubuntu-ports/</span> xenial-security main multiverse restricted universe<br>    deb http:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/ubuntu-ports/</span> xenial-updates main multiverse restricted universe<br>    deb http:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/ubuntu-ports/</span> xenial-backports main multiverse restricted universe<br>    deb-src http:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/ubuntu-ports/</span> xenial main multiverse restricted universe<br>    deb-src http:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/ubuntu-ports/</span> xenial-security main multiverse restricted universe<br>    deb-src http:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/ubuntu-ports/</span> xenial-updates main multiverse restricted universe<br>    deb-src http:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/ubuntu-ports/</span> xenial-backports main multiverse restricted universe<br></code></pre></td></tr></table></figure><p>需要注意的是，在安装过程中可能会需要一些apt无法自己下载的依赖，我们可以在上述kubernetes仓库中下载解决，我需要的是<a href="https://mirrors.tuna.tsinghua.edu.cn/kubernetes/apt/pool/kubernetes-cni_0.7.5-00_arm64_16f686a176ee62fc4f960fd4b272e5e26c73fcced8bd1f8ce9a68a54b2b07e28.deb" target="_blank" rel="noopener">kubernetes-cni_0.7.5</a>和<a href="https://mirrors.tuna.tsinghua.edu.cn/kubernetes/apt/pool/cri-tools_1.13.0-00_arm64_551fb3bc0ac49efe6a2fd37e0c3c081290c661353055d5c933f41d440ca0c7bd.deb" target="_blank" rel="noopener">cri-tools_1.13.0</a>这两个包。</p><p>创建 <code>/etc/docker/daemon.json</code> 使 docker 的 cgroupdriver 为 systemd ，并重启服务。</p><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-meta"># daemon.json内容</span><br>    &#123;<br>      <span class="hljs-string">"exec-opts"</span>: [<span class="hljs-string">"native.cgroupdriver=systemd"</span>],<br>      <span class="hljs-string">"log-driver"</span>: <span class="hljs-string">"json-file"</span>,<br>      <span class="hljs-string">"log-opts"</span>: &#123;<br>        <span class="hljs-string">"max-size"</span>: <span class="hljs-string">"100m"</span><br>      &#125;,<br>      <span class="hljs-string">"storage-driver"</span>: <span class="hljs-string">"overlay2"</span><br>    &#125;<br><span class="hljs-meta"># 重启docker服务</span><br>    sudo systemctl daemon-reload<br>    sudo systemctl restart docker<br></code></pre></td></tr></table></figure><h4 id="Pull-Docker-Images"><a href="#Pull-Docker-Images" class="headerlink" title="Pull Docker Images"></a>Pull Docker Images</h4><p>由于K8s默认使用的<code>.gcr.io</code>官方镜像被墙掉，所以我们需要找到一些替代方法来下载。我们从<strong><a href="https://hub.docker.com/u/mirrorgooglecontainers/" target="_blank" rel="noopener">mirrorgooglecontainers</a></strong>仓库来手动下载镜像，并更改tag来达到离线下载的目的。</p><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs undefined"># Pull mirrorgooglecontainers的images<br>    docker pull mirrorgooglecontainers/kube-apiserver-arm64:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span><br>    docker pull mirrorgooglecontainers/kube-controller-manager-arm64:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span><br>    docker pull mirrorgooglecontainers/kube-scheduler-arm64:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span><br>    docker pull mirrorgooglecontainers/kube-proxy-arm64:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span><br>    docker pull mirrorgooglecontainers/<span class="hljs-keyword">pause</span>-arm64:<span class="hljs-number">3.1</span><br>    docker pull mirrorgooglecontainers/etcd-arm64:<span class="hljs-number">3.3</span><span class="hljs-meta">.10</span><br>    docker pull coredns/coredns:coredns-arm64<br><br># 将mirrorgooglecontainers 的镜像打上k8s.gcr.io 的 tag<br>    docker tag mirrorgooglecontainers/kube-apiserver-arm64:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span> k8s.gcr.io/kube-apiserver:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span><br>    docker tag mirrorgooglecontainers/kube-controller-manager-arm64:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span> k8s.gcr.io/kube-controller-manager:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span><br>    docker tag mirrorgooglecontainers/kube-scheduler-arm64:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span> k8s.gcr.io/kube-scheduler:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span><br>    docker tag mirrorgooglecontainers/kube-proxy-arm64:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span> k8s.gcr.io/kube-proxy:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span><br>    docker tag mirrorgooglecontainers/<span class="hljs-keyword">pause</span>-arm64:<span class="hljs-number">3.1</span> k8s.gcr.io/<span class="hljs-keyword">pause</span>:<span class="hljs-number">3.1</span><br>    docker tag mirrorgooglecontainers/etcd-arm64:<span class="hljs-number">3.3</span><span class="hljs-meta">.10</span> k8s.gcr.io/etcd:<span class="hljs-number">3.3</span><span class="hljs-meta">.10</span><br>    docker tag coredns/coredns:coredns-arm64 k8s.gcr.io/coredns:<span class="hljs-number">1.3</span><span class="hljs-meta">.1</span><br><br># 删除 mirrorgooglecontainers 的镜像，空间够大不建议，否则出错要重新pull<br>    docker rmi mirrorgooglecontainers/kube-apiserver-arm64:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span><br>    docker rmi mirrorgooglecontainers/kube-controller-manager-arm64:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span><br>    docker rmi mirrorgooglecontainers/kube-scheduler-arm64:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span><br>    docker rmi mirrorgooglecontainers/kube-proxy-arm64:v1<span class="hljs-meta">.15</span><span class="hljs-meta">.2</span><br>    docker rmi mirrorgooglecontainers/<span class="hljs-keyword">pause</span>-arm64:<span class="hljs-number">3.1</span><br>    docker rmi mirrorgooglecontainers/etcd-arm64:<span class="hljs-number">3.3</span><span class="hljs-meta">.10</span><br>    docker rmi coredns/coredns:coredns-arm64<br></code></pre></td></tr></table></figure><h4 id="初始化kubernetes"><a href="#初始化kubernetes" class="headerlink" title="初始化kubernetes"></a>初始化kubernetes</h4><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined"># 初始化命令 --apiserver-advertise-address选用。--pod-network-cidr根据后续安装flannel或calico而定，若安装calico请更改为<span class="hljs-number">192.168</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>/<span class="hljs-number">16</span>，本文使用flannel。--ignore-preflight-errors Swap选用。<br>kubeadm init --apiserver-advertise-address=&lt;本机ip&gt; --pod-network-cidr=<span class="hljs-number">10.244</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>/<span class="hljs-number">16</span> --ignore-preflight-errors Swap<br></code></pre></td></tr></table></figure><p>安装成功会出现successfully字样，并提示你进行以下操作：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-comment"># 替换$HOME为你的用户地址执行即可</span><br>  mkdir -p <span class="hljs-variable">$HOME</span>/.kube<br>  sudo cp -i /etc/kubernetes/admin.conf <span class="hljs-variable">$HOME</span>/.kube<span class="hljs-built_in">/config<br></span>  sudo chown $(id -u):$(id -g) <span class="hljs-variable">$HOME</span>/.kube/config<br></code></pre></td></tr></table></figure><p>并记得要记住<code>kubeadm join 192.168.31.73:6443 --token 9ovifx.j5g38h7v8jdieb9z \    --discovery-token-ca-cert-hash sha256:6bf8f538c06613f52c728c80e3eb1c6a4c873d0c6f506aab2b8c785ea228fc36</code>类似信息，以供后续node加入K8s网络，此处注意密钥有效期仅为一天，过期请执行Google解决。</p><p>执行以下操作确定初始化成功。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-comment"># 查看集群信息</span><br>    $ kubectl cluster<span class="hljs-literal">-inf</span>o<br>    Kubernetes <span class="hljs-keyword">master</span> <span class="hljs-title">is</span> running at https://<span class="hljs-number">192.168</span>.<span class="hljs-number">31.73</span>:<span class="hljs-number">6443</span><br>    KubeDNS is running at https://<span class="hljs-number">192.168</span>.<span class="hljs-number">31.73</span>:<span class="hljs-number">6443</span>/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy<br><span class="hljs-comment"># 查看所有node</span><br>    $ kubectl get nodes<br>    NAME                STATUS     ROLES    AGE     <span class="hljs-keyword">VERSION</span><br>    ming-<span class="hljs-keyword">master</span>   <span class="hljs-title">NotReady</span>   <span class="hljs-keyword">master</span>   <span class="hljs-title">3m50s</span>   v1.<span class="hljs-number">15.2</span><br><span class="hljs-comment"># 查看所有Pod</span><br>    $ kubectl get pods --all-namespaces<br></code></pre></td></tr></table></figure><h4 id="安装Flannel网络插件"><a href="#安装Flannel网络插件" class="headerlink" title="安装Flannel网络插件"></a>安装Flannel网络插件</h4><p>我们需要选择Flannel或者Calico网络插件来驱动K8s。</p><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-meta"># 此处可能会遇到无法解析raw.githubusercontent.com的问题，请自行搜索修改host结局。</span><br>    kubectl apply -f https:<span class="hljs-comment">//raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="hljs-meta"># 此处应该可以看到所有 pods为Running状态</span><br>    kubectl <span class="hljs-keyword">get</span> pods --all-namespaces -o wide<br></code></pre></td></tr></table></figure><p>所有配置结束，但是一般配置下来都不会这么顺利，所以请使用<code>kubectl describe pod xxx（pod的id）-n kube-system</code>自行分析、谷歌来进行debug。 </p><h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><p>要保证足够的剩余硬盘空间，否则可能会导致proxy pod创建失败。</p><h3 id="Node篇"><a href="#Node篇" class="headerlink" title="Node篇"></a>Node篇</h3><h4 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h4><p>在树莓派机器上重复Master篇中的<strong>关闭swap、安装kubeadm kubectl kubelet docker-ce以及Pull Docker Images</strong>章节。然后根据前文的密钥加入K8s网络:</p><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">kubeadm join <span class="hljs-number">192.168</span>.<span class="hljs-number">31.73</span>:<span class="hljs-number">6443</span> --token <span class="hljs-number">9</span>ovifx.j<span class="hljs-number">5</span>g<span class="hljs-number">38</span>h<span class="hljs-number">7</span>v<span class="hljs-number">8</span>jdieb<span class="hljs-number">9</span>z \<br>    --discovery-token-ca-cert-hash sha<span class="hljs-number">256</span>:<span class="hljs-number">6</span>bf<span class="hljs-number">8</span>f<span class="hljs-number">538</span><span class="hljs-keyword">c</span><span class="hljs-number">06613</span>f<span class="hljs-number">52</span><span class="hljs-keyword">c</span><span class="hljs-number">728</span><span class="hljs-keyword">c</span><span class="hljs-number">80e3</span>eb<span class="hljs-number">1</span><span class="hljs-keyword">c</span><span class="hljs-number">6</span>a<span class="hljs-number">4</span><span class="hljs-keyword">c</span><span class="hljs-number">873</span>d<span class="hljs-number">0</span><span class="hljs-keyword">c</span><span class="hljs-number">6</span>f<span class="hljs-number">506</span>aab<span class="hljs-number">2</span>b<span class="hljs-number">8</span><span class="hljs-keyword">c</span><span class="hljs-number">785</span>ea<span class="hljs-number">228</span>fc<span class="hljs-number">36</span><br></code></pre></td></tr></table></figure><p>如果执行成功，请在master节点上执行<code>kubectl get nodes</code>查看成功加入的节点。</p><h4 id="注意事项-1"><a href="#注意事项-1" class="headerlink" title="注意事项"></a>注意事项</h4><p>有些成功加入的树莓派节点会非常卡顿，不知道我这几台是不是特殊情况。</p><h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><ul><li><a href="https://sbilly.github.io/post/howto-setup-kubernetes-cluster-on-armbian-linux-based-on-phicomm-n1-arm64-sbc/" target="_blank" rel="noopener">https://sbilly.github.io/post/howto-setup-kubernetes-cluster-on-armbian-linux-based-on-phicomm-n1-arm64-sbc/</a></li><li><a href="https://www.edureka.co/blog/install-kubernetes-on-ubuntu" target="_blank" rel="noopener">https://www.edureka.co/blog/install-kubernetes-on-ubuntu</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>嵌入式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>arm</tag>
      
      <tag>环境部署</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DenseNet in mindspore</title>
    <link href="/2020/09/02/2020-09-02-DenseNet-in-mindspore/"/>
    <url>/2020/09/02/2020-09-02-DenseNet-in-mindspore/</url>
    
    <content type="html"><![CDATA[<h1 id="DenseNet-in-MindSpore"><a href="#DenseNet-in-MindSpore" class="headerlink" title="DenseNet in MindSpore"></a>DenseNet in MindSpore</h1><p>&emsp;关于DenseNet实现的文章有很多，但是MindSpore作为华为研发的新生框架，此类网络结构实现的还不够，所以我在这里使用MindSpore复现了一下DenseNet网络。</p><h2 id="实验配置"><a href="#实验配置" class="headerlink" title="实验配置"></a>实验配置</h2><ul><li>MindSpore 0.5 version</li><li>华为Ascend</li><li>Python 3.7</li></ul><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>&emsp;需要注意的是由于MindSpore初期算子支持不够,所以不能使用AvgPool2d，所以我们在这里用MaxPool2d代替实现。并且由于0.5版本并不支持全局池化，所以我们使用ReduceMean算子代替全局池化.经过实际测试，这种替换对最后的结果影响并不大。</p><h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>&emsp;根据原论文中提供的数据集，我决定采用最简单的CIFAR10作为本次的实验数据。该数据集提供50000个训练样本和10000个测试样本，样本尺寸为32*32。样本被标注为10类。</p><h3 id="实验前准备"><a href="#实验前准备" class="headerlink" title="实验前准备"></a>实验前准备</h3><p>&emsp;由于我们使用的华为的Ascend平台，所以要事先配置好obs桶，将文件和数据集上传到obs桶中，数据集放在<code>cifar10</code>文件夹内。</p><p>&emsp;在我们开始训练时,需要新建一个训练任务，训练文件选择对应的<code>train.py</code>，数据集位置选择<code>cifar10</code>文件夹。具体的操作步骤见华为提供的Ascend平台使用教程。</p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>&emsp;根据论文指导，我们采用growth_rate为12、Depth为100的DenseNet-BC网络结构以及不带Bottleneck和Compression操作的普通DenseNet网络结构。除了ImageNet数据集外，其他数据集均使用3层Dense Block结构，所以我们使用一个<code>Conv+[DB(Dense Block)+TL(Transition Layer)+DB+TL+DB]+BN+ReLU+Pool+Dense</code>的网络结构。</p><p>&emsp;其中Dense Block由一个<code>BN层+ReLU层+3x3的卷积层</code>组成，如果使用DenseBlock-BC网络结构，则还需要加一个<code>BN层+ReLU层(Bottleneck Layer)+1x1的卷积层</code>放在其3x3卷积层前，可以提高运算效率和最后的精度。</p><p>&emsp;其中Transition Layer则由一个<code>BN层+ReLu层+1x1卷积层+AvgPool2d层</code>组成.用来减少特征映射的尺寸，提高计算效率。</p><p>&emsp;在网络的最后，我们使用一个全局池化层，将8x8的特征映射池化为1x1，然后将其展开，用来代替传统的全连接层。</p><p>&emsp;样本初始尺寸为32x32，经过两层Transition Layer，变为16x16和8x8。最后经过全局池化层，变为1x1。</p><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>&emsp;在模型的训练过程中，我们使用动态学习率，初始学习率为0.1，达到50%的epoch时衰减为十分之一，达到75%的epoch时再次衰减为此时的十分之一。</p><p>&emsp;我们根据论文使用0.0001的weight_decay和0.9的momentum。优化器采用随机梯度下降(SGD)。损失函数使用交叉熵损失函数。使用一种简单的随机正态分布将每层的卷积层进行初始化，并使用镜像、裁剪等数据增强操作。</p><p>&emsp;使用的训练epoch为300，最终耗时6小时34分钟，训练loss降至0.001。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>&emsp;测试样本为CIFAR10中的10000个不重复测试样本。最终我们在DenseNet网路结构上实现了94.68%的准确率，在DenseNet-BC网络结构上实现了94.9%的准确率，并未达到论文中的得到的准确率，我猜想是因为Ascend平台的差异，以及我们之前使用的一些替代的算子造成的准确率差异。实验结果如下图所示。</p><p><img src="https://github.com/zhaoyiming/image/raw/master/densenet/loss.jpg" srcset="/img/loading.gif" alt="loss"></p><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><p><code>https://github.com/zhaoyiming/</code></p>]]></content>
    
    
    
    <tags>
      
      <tag>NeuralNetwork</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>java和android中的回调方法</title>
    <link href="/2018/03/18/2018-03-18-java%E5%92%8Candroid%E4%B8%AD%E7%9A%84%E5%9B%9E%E8%B0%83%E6%96%B9%E6%B3%95/"/>
    <url>/2018/03/18/2018-03-18-java%E5%92%8Candroid%E4%B8%AD%E7%9A%84%E5%9B%9E%E8%B0%83%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>最近看第一行代码，遇到了回调这个问题，尽管书中其他知识很细致，却没有对这个作过多解释，看来我的java没学好。这里作一个学习总结。<br>学习主要参考这篇<a href="http://blog.csdn.net/u012441545/article/details/52259466" target="_blank" rel="noopener">文章</a>。<br>回调用语言直接描述就是A类中调用B类中的方法b，B类中反过来调用A类中的方法a，方法a就叫做回调方法。<br><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-type">Class</span> <span class="hljs-type">A</span>实现接口<span class="hljs-type">CallBack</span> callback——背景<span class="hljs-number">1</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">A</span>中包含一个<span class="hljs-keyword">class</span> <span class="hljs-type">B</span>的引用b ——背景2<br><span class="hljs-keyword">class</span> <span class="hljs-type">B</span>有一个参数为callback的方法f(<span class="hljs-type">CallBack</span> <span class="hljs-title">callback</span>) ——背景3<br><span class="hljs-type">A</span>的对象a调用<span class="hljs-type">B</span>的方法 f(<span class="hljs-type">CallBack</span> <span class="hljs-title">callback</span>) ——<span class="hljs-type">A</span>类调用<span class="hljs-type">B</span>类的某个方法 <span class="hljs-type">C</span><br>然后b就可以在f(<span class="hljs-type">CallBack</span> <span class="hljs-title">callback</span>)方法中调用<span class="hljs-type">A</span>的方法 ——<span class="hljs-type">B</span>类调用<span class="hljs-type">A</span>类的某个方法<span class="hljs-type">D</span></span><br></code></pre></td></tr></table></figure></p><p>一个很好的例子<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">有一天小王遇到一个很难的问题，问题是“<span class="hljs-number">1</span> + <span class="hljs-number">1</span> = ?”，就打电话问小李，小李一下子也不知道，就跟小王说，等我办完手上的事情，就去想想答案，小王也不会傻傻的拿着电话去等小李的答案吧，于是小王就对小李说，我还要去逛街，你知道了答案就打我电话告诉我，于是挂了电话，自己办自己的事情，过了一个小时，小李打了小王的电话，告诉他答案是<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure></p><h3 id="异步回调"><a href="#异步回调" class="headerlink" title="异步回调"></a>异步回调</h3><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-keyword">public</span> <span class="hljs-keyword">interface</span> <span class="hljs-title">CallBack</span> &#123;  <br>    <span class="hljs-comment">/** <br>     * 这个是小李知道答案时要调用的函数告诉小王，也就是回调函数 <br>     * @param result 是答案 <br>     */</span>  <br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">solve</span>(<span class="hljs-params">String result</span>)</span>;  <br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-comment">/** <br> * 这个是小王 <br> * @author xiaanming <br> * 实现了一个回调接口CallBack，相当于-----&gt;背景一 <br> */</span>  <br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">Wang</span> <span class="hljs-title">implements</span> <span class="hljs-title">CallBack</span> &#123;  <br>    <span class="hljs-comment">/** <br>     * 小李对象的引用 <br>     * 相当于-----&gt;背景二 <br>     */</span>  <br>    <span class="hljs-keyword">private</span> Li li;   <br>  <br>    <span class="hljs-comment">/** <br>     * 小王的构造方法，持有小李的引用 <br>     * @param li <br>     */</span>  <br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">Wang</span>(<span class="hljs-params">Li li</span>)</span>&#123;  <br>        <span class="hljs-keyword">this</span>.li = li;  <br>    &#125;  <br>      <br>    <span class="hljs-comment">/** <br>     * 小王通过这个方法去问小李的问题 <br>     * @param question  就是小王要问的问题,1 + 1 = ? <br>     */</span>  <br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">askQuestion</span>(<span class="hljs-params">final String question</span>)</span>&#123;  <br>        <span class="hljs-comment">//这里用一个线程就是异步，  </span><br>        <span class="hljs-keyword">new</span> Thread(<span class="hljs-keyword">new</span> Runnable() &#123;  <br>            @<span class="hljs-function">Override  <br>            <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">run</span>(<span class="hljs-params"></span>) </span>&#123;  <br>                <span class="hljs-comment">/** <br>                 * 小王调用小李中的方法，在这里注册回调接口 <br>                 * 这就相当于A类调用B的方法C <br>                 */</span>  <br>                li.executeMessage(Wang.<span class="hljs-keyword">this</span>, question);   <br>            &#125;  <br>        &#125;).start();  <br>          <br>        <span class="hljs-comment">//小网问完问题挂掉电话就去干其他的事情了，诳街去了  </span><br>        play();  <br>    &#125;  <br>  <br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">play</span>(<span class="hljs-params"></span>)</span>&#123;  <br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">"我要逛街去了"</span>);  <br>    &#125;  <br>  <br>    <span class="hljs-comment">/** <br>     * 小李知道答案后调用此方法告诉小王，就是所谓的小王的回调方法 <br>     */</span>  <br>    @<span class="hljs-function">Override  <br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">solve</span>(<span class="hljs-params">String result</span>) </span>&#123;  <br>        System.<span class="hljs-keyword">out</span>.println(<span class="hljs-string">"小李告诉小王的答案是---&gt;"</span> + result);  <br>    &#125;  <br>      <br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight zephir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-comment">/** <br> * 这个就是小李啦 <br> * <span class="hljs-doctag">@author</span> xiaanming <br> * <br> */</span>  <br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Li</span> </span>&#123;  <br>    <span class="hljs-comment">/** <br>     * 相当于B类有参数为CallBack callBack的f()----&gt;背景三 <br>     * <span class="hljs-doctag">@param</span> callBack   <br>     * <span class="hljs-doctag">@param</span> question  小王问的问题 <br>     */</span>  <br>    <span class="hljs-keyword">public</span> void executeMessage(CallBack callBack, String question)&#123;  <br>        System.out.println(<span class="hljs-string">"小王问的问题---&gt;"</span> + question);  <br>          <br>        <span class="hljs-comment">//模拟小李办自己的事情需要很长时间  </span><br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;<span class="hljs-number">10000</span>;i++)&#123;  <br>              <br>        &#125;  <br>          <br>        <span class="hljs-comment">/** <br>         * 小李办完自己的事情之后想到了答案是2 <br>         */</span>  <br>        String result = <span class="hljs-string">"答案是2"</span>;  <br>          <br>        <span class="hljs-comment">/** <br>         * 于是就打电话告诉小王，调用小王中的方法 <br>         * 这就相当于B类反过来调用A的方法D <br>         */</span>  <br>        callBack.solve(result);   <br>  <br>          <br>          <br>    &#125;  <br>      <br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><br><span class="hljs-comment">/** <br> * 测试类 <br> * @author xiaanming <br> * <br> */</span>  <br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Test</span> </span>&#123;  <br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> void main(<span class="hljs-keyword">String</span>[]args)&#123;  <br>        <span class="hljs-comment">/** <br>         * new 一个小李 <br>         */</span>  <br>        Li li = <span class="hljs-keyword">new</span> <span class="hljs-type">Li</span>();  <br>  <br>        <span class="hljs-comment">/** <br>         * new 一个小王 <br>         */</span>  <br>        Wang wang = <span class="hljs-keyword">new</span> <span class="hljs-type">Wang</span>(li);  <br>          <br>        <span class="hljs-comment">/** <br>         * 小王问小李问题 <br>         */</span>  <br>        wang.askQuestion(<span class="hljs-string">"1 + 1 = ?"</span>);  <br>    &#125;  <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="同步回调"><a href="#同步回调" class="headerlink" title="同步回调"></a>同步回调</h3><p>安卓的button点击事件，onclick就是继承于View类的一个回调方法。<br><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-comment">//这个是View的一个回调接口  </span><br><span class="hljs-comment">/** <br> * Interface definition for a callback to be invoked when a view is clicked. <br> */</span>  <br><span class="hljs-keyword">public</span> <span class="hljs-keyword">interface</span> <span class="hljs-title">OnClickListener</span> &#123;  <br>    <span class="hljs-comment">/** <br>     * Called when a view has been clicked. <br>     * <br>     * @param v The view that was clicked. <br>     */</span>  <br>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onClick</span>(<span class="hljs-params">View v</span>)</span>;  <br>&#125;<br></code></pre></td></tr></table></figure></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-keyword">package</span> com.example.demoactivity;  <br>  <br><span class="hljs-keyword">import</span> android.app.<span class="hljs-type">Activity</span>;  <br><span class="hljs-keyword">import</span> android.os.<span class="hljs-type">Bundle</span>;  <br><span class="hljs-keyword">import</span> android.view.<span class="hljs-type">View</span>;  <br><span class="hljs-keyword">import</span> android.view.<span class="hljs-type">View</span>.<span class="hljs-type">OnClickListener</span>;  <br><span class="hljs-keyword">import</span> android.widget.<span class="hljs-type">Button</span>;  <br><span class="hljs-keyword">import</span> android.widget.<span class="hljs-type">Toast</span>;  <br>  <br><span class="hljs-comment">/** <br> * 这个就相当于Class A <br> * @author xiaanming <br> * 实现了 OnClickListener接口----&gt;背景一 <br> */</span>  <br>public <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MainActivity</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Activity</span> <span class="hljs-title">implements</span> <span class="hljs-title">OnClickListener</span></span>&#123;  <br>    <span class="hljs-comment">/** <br>     * Class A 包含Class B的引用-----&gt;背景二 <br>     */</span>  <br>    <span class="hljs-keyword">private</span> <span class="hljs-type">Button</span> button;  <br>  <br>    <span class="hljs-meta">@Override</span>  <br>    public void onCreate(<span class="hljs-type">Bundle</span> savedInstanceState) &#123;  <br>        <span class="hljs-keyword">super</span>.onCreate(savedInstanceState);  <br>        setContentView(<span class="hljs-type">R</span>.layout.activity_main);  <br>        button = (<span class="hljs-type">Button</span>)findViewById(<span class="hljs-type">R</span>.id.button1);  <br>          <br>        <span class="hljs-comment">/** <br>         * Class A 调用View的方法,而Button extends View-----&gt;A类调用B类的某个方法 C <br>         */</span>  <br>        button.setOnClickListener(<span class="hljs-keyword">this</span>);  <br>    &#125;  <br>  <br>    <span class="hljs-comment">/** <br>     * 用户点击Button时调用的回调函数，你可以做你要做的事 <br>     * 这里我做的是用Toast提示OnClick <br>     */</span>  <br>    <span class="hljs-meta">@Override</span>  <br>    public void onClick(<span class="hljs-type">View</span> v) &#123;  <br>        <span class="hljs-type">Toast</span>.makeText(getApplication(), <span class="hljs-string">"OnClick"</span>, <span class="hljs-type">Toast</span>.<span class="hljs-type">LENGTH_LONG</span>).show();  <br>    &#125;  <br>  <br>&#125;<br></code></pre></td></tr></table></figure><p>View类文档如下:<br><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-comment">/** <br> * 这个View就相当于B类 <br> * <span class="hljs-doctag">@author</span> xiaanming <br> * <br> */</span>  <br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">View</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Drawable</span>.<span class="hljs-title">Callback</span>, <span class="hljs-title">KeyEvent</span>.<span class="hljs-title">Callback</span>, <span class="hljs-title">AccessibilityEventSource</span> </span>&#123;  <br>    <span class="hljs-comment">/** <br>     * Listener used to dispatch click events. <br>     * This field should be made private, so it is hidden from the SDK. <br>     * &#123;<span class="hljs-doctag">@hide</span>&#125; <br>     */</span>  <br>    <span class="hljs-keyword">protected</span> OnClickListener mOnClickListener;  <br>      <br>    <span class="hljs-comment">/** <br>     * setOnClickListener()的参数是OnClickListener接口------&gt;背景三 <br>     * Register a callback to be invoked when this view is clicked. If this view is not <br>     * clickable, it becomes clickable. <br>     * <br>     * <span class="hljs-doctag">@param</span> l The callback that will run <br>     * <br>     * <span class="hljs-doctag">@see</span> #setClickable(boolean) <br>     */</span>  <br>      <br>    <span class="hljs-keyword">public</span> void setOnClickListener(OnClickListener l) &#123;  <br>        <span class="hljs-keyword">if</span> (!isClickable()) &#123;  <br>            setClickable(<span class="hljs-keyword">true</span>);  <br>        &#125;  <br>        mOnClickListener = l;  <br>    &#125;  <br>      <br>      <br>    <span class="hljs-comment">/** <br>     * Call this view's OnClickListener, if it is defined. <br>     * <br>     * <span class="hljs-doctag">@return</span> True there was an assigned OnClickListener that was called, false <br>     *         otherwise is returned. <br>     */</span>  <br>    <span class="hljs-keyword">public</span> boolean performClick() &#123;  <br>        sendAccessibilityEvent(AccessibilityEvent.TYPE_VIEW_CLICKED);  <br>  <br>        <span class="hljs-keyword">if</span> (mOnClickListener != <span class="hljs-keyword">null</span>) &#123;  <br>            playSoundEffect(SoundEffectConstants.CLICK);  <br>              <br>            <span class="hljs-comment">//这个不就是相当于B类调用A类的某个方法D，这个D就是所谓的回调方法咯  </span><br>            mOnClickListener.onClick(this);  <br>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;  <br>        &#125;  <br>  <br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;  <br>    &#125;  <br>&#125;<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
    <categories>
      
      <category>基础</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>杨辉三角</title>
    <link href="/2018/03/17/2018-03-17-%E6%9D%A8%E8%BE%89%E4%B8%89%E8%A7%92/"/>
    <url>/2018/03/17/2018-03-17-%E6%9D%A8%E8%BE%89%E4%B8%89%E8%A7%92/</url>
    
    <content type="html"><![CDATA[<p>今天参加了一个小笔试，提到杨辉三角居然又忘了，做了无数次…<br>看来没真的理解。<br>主要卡在“这中间的空格怎么实现啊！！”<br>发现这个空格无需关注。<br>上代码</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">void</span>)</span><br></span>&#123;<br><span class="hljs-keyword">int</span> a[<span class="hljs-number">6</span>][<span class="hljs-number">6</span>];<br><span class="hljs-keyword">int</span> i,x,y;<br><span class="hljs-keyword">for</span>(x=<span class="hljs-number">0</span>;x&lt;<span class="hljs-number">6</span>;x++) &#123;<br><span class="hljs-keyword">for</span>(i=<span class="hljs-number">0</span>;i&lt;<span class="hljs-number">6</span>-x;i++)&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">" "</span>);<br>&#125;<br><span class="hljs-keyword">for</span>(y=<span class="hljs-number">0</span>;y&lt;=x;y++)&#123;<br><span class="hljs-keyword">if</span>(y==<span class="hljs-number">0</span>||x==y)<br>a[x][y]=<span class="hljs-number">1</span>;<br><span class="hljs-keyword">else</span><br>a[x][y]=a[x<span class="hljs-number">-1</span>][y]+a[x<span class="hljs-number">-1</span>][y<span class="hljs-number">-1</span>];<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">"%d "</span>,a[x][y]);<br>&#125;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">"\n"</span>);<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>基础</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>5$首年付vps</title>
    <link href="/2018/03/01/2018-03-01-5$%E9%A6%96%E5%B9%B4%E4%BB%98vps/"/>
    <url>/2018/03/01/2018-03-01-5$%E9%A6%96%E5%B9%B4%E4%BB%98vps/</url>
    
    <content type="html"><![CDATA[<h2 id="准备工作："><a href="#准备工作：" class="headerlink" title="准备工作："></a>准备工作：</h2><ul><li>一个用于校园认证的大学邮箱。</li><li>一个<a href="http://github.com" target="_blank" rel="noopener">Github账号</a>。</li><li>一个paypal账号。<h2 id="获取Github-Student-Developer-Pack的优惠"><a href="#获取Github-Student-Developer-Pack的优惠" class="headerlink" title="获取Github Student Developer Pack的优惠"></a>获取Github Student Developer Pack的优惠</h2>打开<a href="https://education.github.com/pack/" target="_blank" rel="noopener">Github学生认证界面</a>,点击Get Your Pack。登录Github账号，之前登录过的应该会直接进入认证。<img src="http://imglf4.nosdn.127.net/img/WU1zZkNURmhGdm16M0pieWhqMDNIVkhETnFrV2o5MXVrQmhUMlUvN0FSTnFEeHhmV01MOTdnPT0.png?imageView&amp;thumbnail=500x0&amp;quality=96&amp;stripmeta=0" srcset="/img/loading.gif" alt="提示认证"><br>提示认证，点击Yes按钮。<br>接着进入认证界面。根据页面提示填入相应内容，School name填写学校英文名就可以，最后一栏How do you plan to use Github？象征性写两句就可以。如果没有学校邮箱也可以，可以上传学生卡照片之类的。验证比较宽松，很容易就能通过，第一次没有申请成功可以修改一下再尝试。<br>验证成功后在My pack中可以找到DigitalOcean的50刀优惠码。<img src="http://imglf5.nosdn.127.net/img/WU1zZkNURmhGdm16M0pieWhqMDNIZjBJQmQwcU1mS3dKbkFMZTl3VWU2QUJBdVdzc3FSaXV3PT0.png?imageView&amp;thumbnail=500x0&amp;quality=96&amp;stripmeta=0" srcset="/img/loading.gif" alt="DigitalOcean优惠码"><h2 id="获取vps"><a href="#获取vps" class="headerlink" title="获取vps"></a>获取vps</h2><h3 id="注册DigitalOcean账号这里是我的邀请链接，可以额外获得10-，官网直接申请的话并没有orz。"><a href="#注册DigitalOcean账号这里是我的邀请链接，可以额外获得10-，官网直接申请的话并没有orz。" class="headerlink" title="注册DigitalOcean账号这里是我的邀请链接，可以额外获得10$，官网直接申请的话并没有orz。"></a>注册<a href="https://m.do.co/c/7b48d52d438e" target="_blank" rel="noopener">DigitalOcean账号</a>这里是我的邀请链接，可以额外获得10$，官网直接申请的话并没有orz。</h3><h3 id="激活优惠码"><a href="#激活优惠码" class="headerlink" title="激活优惠码"></a>激活优惠码</h3><img src="http://imglf3.nosdn.127.net/img/WU1zZkNURmhGdm16M0pieWhqMDNIU0V3eHAvK3ZUSENJK0RDRjJjN1phdmluelNVWUtPbkx3PT0.png?imageView&amp;thumbnail=500x0&amp;quality=96&amp;stripmeta=0" srcset="/img/loading.gif" alt="billing"><br>在Setting界面找到Billing选项卡，在下拉的Promo Code中填入刚才在学生认证中看到的优惠码，如果出现错误可以找客服沟通一下。<br><img src="http://imglf6.nosdn.127.net/img/WU1zZkNURmhGdm16M0pieWhqMDNIZG94MGR2d1ZDbzAyMDlQUzZFMDEzZXQ0MktRWTVOeCtRPT0.jpg?imageView&amp;thumbnail=500x0&amp;quality=96&amp;stripmeta=0&amp;type=jpg" srcset="/img/loading.gif" alt="promo code"><h3 id="验证账户"><a href="#验证账户" class="headerlink" title="验证账户"></a>验证账户</h3>虽然DigitalOcean优惠码已经激活了，但是这时候还不能购买VPS，需要账户验证。账户验证有两种方式，一是绑定信用卡，二是通过paypal向账户充值5美元。根据提示付款解锁吧，这里就不再赘述了，paypal是可以绑定国内储蓄卡的。<h3 id="购买VPS"><a href="#购买VPS" class="headerlink" title="购买VPS"></a>购买VPS</h3>点击首页的Create按钮，选择Droplets，进入购买。选择一个发行版Linux，这里可以选一个任意版本的Ubuntu，往下找到5美元月付的选项卡，再往下选择地区，用<a href="http://speedtest-sfo1.digitalocean.com/" target="_blank" rel="noopener">测速网址</a>找到一个网速最快，延迟最小的地区。本地联通一般是sfo圣弗兰西斯科机房较优。其他没有提到的选项不用管，最后点击Create完成创建。<h2 id="酸酸乳的搭建"><a href="#酸酸乳的搭建" class="headerlink" title="酸酸乳的搭建"></a>酸酸乳的搭建</h2>这里先放上<a href="https://shadowsocks.be/9.html" target="_blank" rel="noopener">秋水逸冰的一键脚本</a>。<br>从刚才创建的页面开始<img src="http://imglf6.nosdn.127.net/img/WU1zZkNURmhGdmxBa3hFSWFKeEdZZ1VrSFoxZkhYNGxCSmhzQ24vRGpvTmJuKzZQWXNQWWNRPT0.png?imageView&amp;thumbnail=500x0&amp;quality=96&amp;stripmeta=0" srcset="/img/loading.gif" alt="服务器界面"><br>点击Access Console按钮，进入网页控制台，你邮箱之前应该会受到dg发来的服务器密码，输入，会提示你创建密码，需要注意的是unix特性输入的密码是不会显示的，直接输入即可。<br>成功进入服务器后，参见秋水大大的博客直接设置即可。设置完后，在相应系统的应用中输入设置的信息即可。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>vps</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>安卓开发中遇到的问题</title>
    <link href="/2018/02/13/2018-02-13-%E5%AE%89%E5%8D%93%E5%BC%80%E5%8F%91%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <url>/2018/02/13/2018-02-13-%E5%AE%89%E5%8D%93%E5%BC%80%E5%8F%91%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h3 id="关于使用沉浸式状态栏后，Toast通知文字不居中。"><a href="#关于使用沉浸式状态栏后，Toast通知文字不居中。" class="headerlink" title="关于使用沉浸式状态栏后，Toast通知文字不居中。"></a>关于使用沉浸式状态栏后，Toast通知文字不居中。</h3><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-selector-tag">Toast</span><span class="hljs-selector-class">.makeText</span>(getApplicationContext(),<span class="hljs-string">"You Clicked Search"</span>,Toast.LENGTH_SHORT).<br>                        <span class="hljs-selector-tag">show</span>();<br></code></pre></td></tr></table></figure><p>在使用第一个参数时，不能使用getBaseContext()或者this，而应该改为getApplicationContext()。</p><h3 id="关于toolbar中返回按钮点击无效"><a href="#关于toolbar中返回按钮点击无效" class="headerlink" title="关于toolbar中返回按钮点击无效"></a>关于toolbar中返回按钮点击无效</h3><p>在大年初二犯了这个很蠢的错误，把书上的android.R.id.home想当然地看成同toolbar上其他按钮一样的R.id.xx,导致点击无效。在<a href="https://stackoverflow.com/questions/22778902/actionbar-back-button-not-working-in-android" target="_blank" rel="noopener">stackoverflow</a>上找到了案例。<br>记此以区别。</p><h3 id="关于Tablayout-ViewPages-Fragment实现顶部导航栏"><a href="#关于Tablayout-ViewPages-Fragment实现顶部导航栏" class="headerlink" title="关于Tablayout+ViewPages+Fragment实现顶部导航栏"></a>关于Tablayout+ViewPages+Fragment实现顶部导航栏</h3><p>真的好麻烦啊，头疼！<br><a href="https://www.jianshu.com/p/ce1d060573ba" target="_blank" rel="noopener">参考文章</a></p><h4 id="实现步骤："><a href="#实现步骤：" class="headerlink" title="实现步骤："></a>实现步骤：</h4><ol><li>添加依赖 </li><li>创建Fragment</li><li>创建Fragment对应Activity</li><li>定义适配器Adapter类：MyFragmentPagerAdapter</li><li>修改主布局activity</li><li>修改主活动MainActivity<h3 id="关于Radiobutton选中时颜色改变"><a href="#关于Radiobutton选中时颜色改变" class="headerlink" title="关于Radiobutton选中时颜色改变"></a>关于Radiobutton选中时颜色改变</h3>开始想到创建颜色选择器，<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="php"><span class="hljs-meta">&lt;?</span>xml version=<span class="hljs-string">"1.0"</span> encoding=<span class="hljs-string">"utf-8"</span><span class="hljs-meta">?&gt;</span></span><br><span class="hljs-tag">&lt;<span class="hljs-name">selector</span> <span class="hljs-attr">xmlns:android</span>=<span class="hljs-string">"http://schemas.android.com/apk/res/android"</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">item</span> <span class="hljs-attr">android:color</span>=<span class="hljs-string">"@color/radioButtonChecked"</span> <span class="hljs-attr">android:state_checked</span>=<span class="hljs-string">"true"</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">item</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">item</span> <span class="hljs-attr">android:color</span>=<span class="hljs-string">"@color/radioButtonunChecked"</span> <span class="hljs-attr">android:state_checked</span>=<span class="hljs-string">"false"</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">item</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">se</span></span><br></code></pre></td></tr></table></figure></li></ol><p>在radiogroup设置为<code>Android:textcolor</code>发现无效,设置为<code>Andoroid:backgroud</code>时出现崩溃。<br>经过多处查证后，一般都为重绘改变颜色。见<a href="http://bbs.csdn.net/topics/60138033" target="_blank" rel="noopener">csdn楼层</a>。<br>先挖坑待填。</p>]]></content>
    
    
    <categories>
      
      <category>开发</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Android</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>catalog和category的区别</title>
    <link href="/2018/02/10/2018-02-10-catalog%E5%92%8Ccategory%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <url>/2018/02/10/2018-02-10-catalog%E5%92%8Ccategory%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<p>#Difference between the “catalog” and “category”?</p><p>A catalog is a list of items in some order or system of classification.<br>It can also be used as a verb meaning to put items into a catalog.</p><p>A category is a group or set of things or people that have one or more common characteristics.</p><p>A catalog may contain one or more categories. A catalog can also be in a category - “a tool catalog” or “a fashion catalog”.</p>]]></content>
    
    
    <categories>
      
      <category>英语学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>为你的博客添加Fork me on Github</title>
    <link href="/2018/02/05/2018-02-05-%E4%B8%BA%E4%BD%A0%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0Fork%20me%20on%20Github/"/>
    <url>/2018/02/05/2018-02-05-%E4%B8%BA%E4%BD%A0%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0Fork%20me%20on%20Github/</url>
    
    <content type="html"><![CDATA[<h1 id="为你的博客添加Fork-me-on-Github"><a href="#为你的博客添加Fork-me-on-Github" class="headerlink" title="为你的博客添加Fork me on Github"></a>为你的博客添加Fork me on Github</h1><p>利用作者写好的代码很容易实现。</p><h3 id="复制源码"><a href="#复制源码" class="headerlink" title="复制源码"></a>复制源码</h3><p>从<a href="https://github.com/blog/273-github-ribbons" target="_blank" rel="noopener">Github地址</a>中复制一个你喜欢的样式，修改替换<code>&lt;a href=&quot;xxx&quot;&gt;</code>中的Github地址为你自己的Github地址。</p><h3 id="修改主题文件"><a href="#修改主题文件" class="headerlink" title="修改主题文件"></a>修改主题文件</h3><p>复制代码到博客目录下(以material主题为例)<code>themes\material\layout\layout.ejs</code>。其他主题大体相同，不同主题<code>layout</code>文件类型可能不同。<br>修改后如图<br><img src="http://imglf3.nosdn.127.net/img/WU1zZkNURmhGdmtOV1FwRGUrL3BReUYxeDVTMVk5SVlNQ1BBdDBoWk00QW40U1JVM0NRVDhnPT0.png?imageView&amp;thumbnail=1894y859&amp;type=png&amp;quality=96&amp;stripmeta=0" srcset="/img/loading.gif" alt="layout文件截图"><br>添加如图位置即可，不同主题可能代码不相同，如果添加后未生效，尽量在主函数体中添加。</p>]]></content>
    
    
    <categories>
      
      <category>学外拓展</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博客</tag>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Windows下使用Github+hexo搭建博客</title>
    <link href="/2018/02/01/2018-02-01-Windows%E4%B8%8B%E4%BD%BF%E7%94%A8Github-hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"/>
    <url>/2018/02/01/2018-02-01-Windows%E4%B8%8B%E4%BD%BF%E7%94%A8Github-hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="Windows下在Github上搭建hexo博客"><a href="#Windows下在Github上搭建hexo博客" class="headerlink" title="Windows下在Github上搭建hexo博客"></a>Windows下在Github上搭建hexo博客</h1><h2 id="关于第一篇技术博客，介绍如何在Windows环境下通过Github-pages搭建hexo，包括如何从WordPress转移博客到hexo上。"><a href="#关于第一篇技术博客，介绍如何在Windows环境下通过Github-pages搭建hexo，包括如何从WordPress转移博客到hexo上。" class="headerlink" title="关于第一篇技术博客，介绍如何在Windows环境下通过Github pages搭建hexo，包括如何从WordPress转移博客到hexo上。"></a>关于第一篇技术博客，介绍如何在Windows环境下通过Github pages搭建hexo，包括如何从WordPress转移博客到hexo上。</h2><h2 id="hexo搭建"><a href="#hexo搭建" class="headerlink" title="hexo搭建"></a>hexo搭建</h2><h3 id="搭建博客前小小的工作"><a href="#搭建博客前小小的工作" class="headerlink" title="搭建博客前小小的工作"></a>搭建博客前小小的工作</h3><h4 id="1-Github注册"><a href="#1-Github注册" class="headerlink" title="1.Github注册"></a>1.Github注册</h4><p>在此不再赘述，在<a href="https://github.com/" target="_blank" rel="noopener">Github官网</a>注册即可。</p><h4 id="2-安装node-js"><a href="#2-安装node-js" class="headerlink" title="2.安装node.js"></a>2.安装node.js</h4><p><a href="https://nodejs.org/en/" target="_blank" rel="noopener">node.js官网</a>下载安装。安装完毕后打开命令行界面输入<code>node -v</code>如图。<br><img src="http://imglf4.nosdn.127.net/img/WU1zZkNURmhGdm5la21NN1A5OVhFZ2N4SVFVWmpzRlRnVXpqTDBaV3ZrM21DSGIxck42Q3FBPT0.png?imageView&amp;amp;amp;amp;amp;amp;thumbnail=500x0&amp;amp;amp;amp;amp;amp;quality=96&amp;amp;amp;amp;amp;amp;stripmeta=0" srcset="/img/loading.gif" alt="node.js成功安装截图"></p><h4 id="3-安装git"><a href="#3-安装git" class="headerlink" title="3.安装git"></a>3.安装git</h4><p><a href="https://git-scm.com/" target="_blank" rel="noopener">Git官网</a>安装提示默认选项安装即可。安装完毕后打开命令行输入<code>git --version</code>成功安装如图所示。<br><img src="http://imglf5.nosdn.127.net/img/WU1zZkNURmhGdm4wbHJBR3d5TGtRRUgydHZyOFllY1FqR1RYS212aDJsMnlDMHAvODVxWjhRPT0.png?imageView&amp;amp;amp;amp;amp;amp;thumbnail=500x0&amp;amp;amp;amp;amp;amp;quality=96&amp;amp;amp;amp;amp;amp;stripmeta=0" srcset="/img/loading.gif" alt="git成功安装截图"><br>git安装成功后需要添加邮箱和用户名，将代码中双引号中的部分替换成你的用户名，范例邮箱替换成你的邮箱。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs undefined">$ git<span class="hljs-built_in"> config </span>--global user.name <span class="hljs-string">"John Doe"</span> <br>$ git<span class="hljs-built_in"> config </span>--global user.email johndoe@example.com<br></code></pre></td></tr></table></figure><p>添加完后我们需要添加SSH Key到你的Github账户，添加SSH Key是为了让你的Github账户可以绑定你的机器。<br>打开Git Bash执行代码：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-selector-tag">ssh-keygen</span> <span class="hljs-selector-tag">-t</span> <span class="hljs-selector-tag">rsa</span> <span class="hljs-selector-tag">-C</span> "<span class="hljs-selector-tag">zym736531683</span>@<span class="hljs-keyword">gmail</span>.<span class="hljs-keyword">com</span>"<br></code></pre></td></tr></table></figure><p>Git Bash一般可以在左下角开始菜单栏中找到，同样将邮箱替换为你的邮箱。成功之后会在用户的.ssh目录下生成两个文件，如下图。.shh目录一般在:c盘 -&gt; 用户（user）-&gt; 用户名（我的为鸣）-&gt;.ssh<br><img src="http://imglf3.nosdn.127.net/img/WU1zZkNURmhGdms3ZmpBQldTYTJBNnZRWWJpZFlCLyticHFSdnlIQ0lwZktWaERwSmlOZm9BPT0.png?imageView&amp;amp;amp;amp;amp;amp;thumbnail=500x0&amp;amp;amp;amp;amp;amp;quality=96&amp;amp;amp;amp;amp;amp;stripmeta=0" srcset="/img/loading.gif" alt=".ssh目录"><br>使用<a href="https://notepad-plus-plus.org/" target="_blank" rel="noopener">Notepad++</a>或其他应用打开<code>id rsa.pub</code>文件复制所有内容<br>打开Github-&gt; 点击头像 -&gt; Settings -&gt; SSH and GPG keys -&gt;New SSH keys -&gt; 粘贴刚才复制的内容至Key框中</p><h3 id="搭建博客"><a href="#搭建博客" class="headerlink" title="搭建博客"></a>搭建博客</h3><h4 id="hexo本地设置"><a href="#hexo本地设置" class="headerlink" title="hexo本地设置"></a>hexo本地设置</h4><p>在硬盘中新建一个文件夹用来存放你的博客数据，右键文件夹点击<code>Git Bash Here</code><br>在弹出的CLI中输入：</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">npm install -g hexo-<span class="hljs-keyword">cli</span><br></code></pre></td></tr></table></figure><p>安装完毕后输入hexo检测是否安装成功<br><img src="http://imglf4.nosdn.127.net/img/WU1zZkNURmhGdms3ZmpBQldTYTJBMEg3NWlFSzlpbWpmRlNoMld2OTBDZU8rVnEvYW12bVFnPT0.png?imageView&amp;amp;amp;amp;amp;amp;thumbnail=500x0&amp;amp;amp;amp;amp;amp;quality=96&amp;amp;amp;amp;amp;amp;stripmeta=0" srcset="/img/loading.gif" alt="hexo安装成功截图"><br>需要注意的是，在输入命令后CLI可能没有立即反应，耐心等待即可。<br>初始化hexo,后一个hexo为创建文件夹名，可修改</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-attribute">hexo init hexo</span><br></code></pre></td></tr></table></figure><p>初始化成功后显示<code>Start blogging with Hexo!</code><br>接着依次输入：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">cd hexo<br>npm install     <span class="hljs-comment">// 安装依赖文件</span><br>hexo <span class="hljs-keyword">generate</span>   <span class="hljs-comment">//生成静态文件</span><br></code></pre></td></tr></table></figure><p>完成后启动服务器</p><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">hexo <span class="hljs-keyword">server</span><br></code></pre></td></tr></table></figure><p>在浏览器中输入<code>http://localhost:4000/</code>即可看到默认的网站。假如没有成功打开请检查前面的步骤。关于安装福昕阅读器会占用4000端口的问题，请输入<code>hexo server -p 5000</code>进行尝试。</p><h4 id="Github-Page配置"><a href="#Github-Page配置" class="headerlink" title="Github Page配置"></a>Github Page配置</h4><p>在Github首页点击<code>New repository</code><br>在新的页面中<code>Repository name</code>输入</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">xxx<span class="hljs-selector-class">.github</span><span class="hljs-selector-class">.io</span><br></code></pre></td></tr></table></figure><p>xxx最好为Github用户名</p><h4 id="部署到Github"><a href="#部署到Github" class="headerlink" title="部署到Github"></a>部署到Github</h4><p>用刚才下载的Notepad++打开hexo目录下的配置文件<code>_config.yml</code>在文件最后面的deploy属性中加入代码修改为：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined"><span class="hljs-attribute">type</span>: git<br><span class="hljs-attribute">repository</span>: git<span class="hljs-variable">@github</span>.<span class="hljs-attribute">com</span>:WX-JIN/WX-JIN.github.io.git<br><span class="hljs-attribute">branch</span>: master<br></code></pre></td></tr></table></figure><p>千万注意每个冒号后面要加空格，否则hexo g会失败。详情配置见<a href="https://hexo.io/zh-cn/docs/configuration.html" target="_blank" rel="noopener">官方文档</a>。<br>通过CLI在hexo目录下输入命令安装hexo-deployer-git插件：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">npm <span class="hljs-keyword">install</span> hexo-deployer-git <span class="hljs-comment">--save</span><br></code></pre></td></tr></table></figure><p>重要的三个命令：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs undefined">hexo clean <span class="hljs-comment">//若变更主题后不生效，需执行</span><br>hexo <span class="hljs-keyword">generate</span>  <span class="hljs-comment">//简写为hexo g ，生成静态文件，变更文章后执行</span><br>hexo deploy <span class="hljs-comment">//简写为hexo d 部署至Github</span><br></code></pre></td></tr></table></figure><p>一般变更文章需执行后两个，可结合为<code>hexo d -g</code>，至此已经大工告成。</p><h2 id="从其他博客如Wordpress转移到hexo"><a href="#从其他博客如Wordpress转移到hexo" class="headerlink" title="从其他博客如Wordpress转移到hexo"></a>从其他博客如Wordpress转移到hexo</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">hexo migrate <span class="hljs-tag">&lt;<span class="hljs-name">文件目录</span>&gt;</span><br></code></pre></td></tr></table></figure><p>从wordpress导出文件，如何导出不再赘述，文件目录为绝对路径，可将文件导出后放入hexo文件夹根目录<code>hexo migrate &lt;文件&gt;</code></p>]]></content>
    
    
    <categories>
      
      <category>学外拓展</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博客</tag>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
